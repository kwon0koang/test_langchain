{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_community.chat_models import ChatOllama\n",
                "from langchain_community.embeddings import OllamaEmbeddings\n",
                "from langchain_community.vectorstores import FAISS\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
                "from langserve import RemoteRunnable\n",
                "import bs4\n",
                "from langchain_community.document_loaders import TextLoader\n",
                "from langchain_community.document_loaders import WebBaseLoader\n",
                "from langchain_community.document_loaders import PyMuPDFLoader\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from langchain import hub\n",
                "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
                "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
                "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
                "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
                "from langchain_core.pydantic_v1 import BaseModel, Field\n",
                "from langchain_core.vectorstores import VectorStoreRetriever\n",
                "from langchain_core.documents.base import Document\n",
                "from langchain.agents import AgentExecutor\n",
                "from langchain.tools.retriever import create_retriever_tool\n",
                "import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from dotenv import load_dotenv\n",
                "\n",
                "# 환경변수 로드 (.env)\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "llm = ChatOpenAI(\n",
                "    base_url = \"http://sionic.chat:8001/v1\",\n",
                "    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\",\n",
                "    model=\"xionic-ko-llama-3-70b\",\n",
                "    temperature=0\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/kwon0koang/Library/Caches/pypoetry/virtualenvs/test-langchain-PJ4Uqdqm-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
                        "  warn_deprecated(\n",
                        "/Users/kwon0koang/Library/Caches/pypoetry/virtualenvs/test-langchain-PJ4Uqdqm-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[Tool(name='saved_news_search', description='엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다. 엔비디아, 퍼플렉시티, 라마3 관련 정보는 이 도구를 사용해야 한다', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x10646a5c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x2bab41bb0>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x10646aac0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x2bab41bb0>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')),\n",
                            " Tool(name='pdf_search', description='생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다. 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보는 이 도구를 사용해야 한다', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x10646a5c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x2bab41c70>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x10646aac0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x2bab41c70>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain.tools.retriever import create_retriever_tool\n",
                "\n",
                "embeddings = HuggingFaceEmbeddings(\n",
                "    model_name=\"BAAI/bge-m3\",\n",
                "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
                "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
                ")\n",
                "\n",
                "# 로컬 DB 불러오기\n",
                "MY_NEWS_INDEX = \"MY_NEWS_INDEX\"\n",
                "vectorstore1 = FAISS.load_local(MY_NEWS_INDEX, \n",
                "                               embeddings, \n",
                "                               allow_dangerous_deserialization=True)\n",
                "retriever1 = vectorstore1.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 유사도 높은 3문장 추출\n",
                "MY_PDF_INDEX = \"MY_PDF_INDEX\"\n",
                "vectorstore2 = FAISS.load_local(MY_PDF_INDEX, \n",
                "                               embeddings, \n",
                "                               allow_dangerous_deserialization=True)\n",
                "retriever2 = vectorstore2.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 유사도 높은 3문장 추출\n",
                "\n",
                "retriever_tool1 = create_retriever_tool(\n",
                "    retriever1,\n",
                "    name=\"saved_news_search\",\n",
                "    description=\"엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다. 엔비디아, 퍼플렉시티, 라마3 관련 정보는 이 도구를 사용해야 한다\",\n",
                ")\n",
                "\n",
                "retriever_tool2 = create_retriever_tool(\n",
                "    retriever2,\n",
                "    name=\"pdf_search\",\n",
                "    description=\"생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다. 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보는 이 도구를 사용해야 한다\",\n",
                ")\n",
                "\n",
                "tools = [retriever_tool1, retriever_tool2]\n",
                "tools"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'teddynote', 'lc_hub_repo': 'react-chat-json-korean', 'lc_hub_commit_hash': '246b7852986ad9370b8d41310461e4e52a947ea1b67bf034722f4447a4caa064'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input', 'tool_names', 'tools'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n{tools}\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\ The action to take. Must be one of {tool_names}\\n    \"action_input\": string \\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\ You should put what you want to return to use here. You must write the response in Korean.\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\nUse search tools to answer the following question in Korean:\\n{input}')), SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad'], template='Write in Korean:\\n{agent_scratchpad}'))])"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "json_prompt = hub.pull(\"teddynote/react-chat-json-korean\")\n",
                "json_prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.agents import create_json_chat_agent\n",
                "from langchain.agents import AgentExecutor\n",
                "\n",
                "agent = create_json_chat_agent(llm, tools, json_prompt)\n",
                "agent_executor = AgentExecutor(\n",
                "    agent=agent,\n",
                "    tools=tools,\n",
                "    verbose=True,\n",
                "    handle_parsing_errors=True,\n",
                "    return_intermediate_steps=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
                        "\u001b[32;1m\u001b[1;3m```\n",
                        "{\n",
                        "    \"action\": \"pdf_search\",\n",
                        "    \"action_input\": \"생성형 AI 도입에 따른 규제 연구 책임자는\"\n",
                        "}\n",
                        "```\u001b[0m\u001b[33;1m\u001b[1;3mii\n",
                        "【2023년도 중앙선거관리위원회 정책연구용역 보고서】\n",
                        "『생성형 AI 신기술 도입에 따른 \n",
                        "선거 규제 연구』\n",
                        "연구책임자 : \n",
                        "김\n",
                        " 주\n",
                        " 희(국 립 부 경 대 학 교)\n",
                        "공동연구자 :\n",
                        "차\n",
                        " 재\n",
                        " 권(국 립 부 경 대 학 교)\n",
                        "김\n",
                        " 현\n",
                        " 정(동 아 대 학 교)\n",
                        "조\n",
                        " 성\n",
                        " 복(국 민 대 학 교)\n",
                        "연구보조원 : \n",
                        "박\n",
                        " 서\n",
                        " 현(국 립 부 경 대 학 교)\n",
                        "권\n",
                        " 수\n",
                        " 민(국 립 부 경 대 학 교)\n",
                        "본 연구보고서는 2023년도 중앙선거관리위원회 정책연구용역 과제로서 연구내용은 중앙\n",
                        "선거관리위원회의 공식 견해가 아님.\n",
                        "\n",
                        "15\n",
                        "나. 생성형 AI 규제 유형화\n",
                        "○본 연구에서는 주요국의 생성형 AI 규제 동향을 ‘AI 관련 입법 목적’ \n",
                        "및 ‘AI에 대한 규제는 규제원칙 및 방식’에 따라 아래와 같이 분류한다.\n",
                        "○다수 국가들이 AI 규제를 준비하고 있는 가운데, 미국과 EU는 AI에 대\n",
                        "한 규제 입법에 앞장서 왔다. 미국과 EU의 규제 내용 및 동향 대한 자\n",
                        "세한 내용은 4장에서 다룰 것이다.\n",
                        "- 2019년 트럼프 전 대통령이 행정명령 제13859호에서 “미국 인공지\n",
                        "능 구상”을 공표한 이후, 미국은 AI 관련 규제를 입법하였다. 본 연\n",
                        "구에서는 AI 연구개발과 훈련과 관련한 법률인 「생성적 적대 신경\n",
                        "망 출력물 확인법」, 「국가 인공지능 구상법 2020」을 분석한다. 또\n",
                        "한 연방정부가 제정한 AI 사용에 관한 행정명령 제13960호, 「정부인\n",
                        "공지능법 2020」, 「조달인력의 인공지능 역량강화법」, 「미국인공\n",
                        "지능진흥법」 등과 더불어 최근 논의되고 있는 생성형 AI 기술 규제\n",
                        "\n",
                        "- (제8조) 생성형 AI 기술 연구·개발 과정에서 데이터 라벨링을 수행하\n",
                        "는 경우 서비스 제공자는 이 방법의 요구사항에 따라 △명확하고 구체\n",
                        "적이며 실행 가능한 라벨링 규칙을 제정하고, △데이터 라벨링 품질 \n",
                        "평가를 수행하며, △라벨링 내용의 정확성을 확인하기 위해 샘플링을 \n",
                        "수행해야 함. 또한 △라벨링 담당자에게 필요한 교육을 제공하고 준법\n",
                        "의식을 향상시키며, △라벨링 담당자의 표준화된 작업 수행을 감독·\n",
                        "지도해야 함\u001b[0m\u001b[32;1m\u001b[1;3m```\n",
                        "{\n",
                        "    \"action\": \"Final Answer\",\n",
                        "    \"action_input\": \"생성형 AI 도입에 따른 규제 연구 책임자는 김주희(국립부경대학교)입니다.\"\n",
                        "}\n",
                        "```\u001b[0m\n",
                        "\n",
                        "\u001b[1m> Finished chain.\u001b[0m\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'생성형 AI 도입에 따른 규제 연구 책임자는 김주희(국립부경대학교)입니다.'"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "response = agent_executor.invoke(\n",
                "    # {\"input\": \"퍼플렉시티가 투자받은 금액?\"}\n",
                "    {\"input\": \"생성형 AI 도입에 따른 규제 연구 책임자는?\"}\n",
                ") \n",
                "response[\"output\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "test-langchain-lw2NDlv9-py3.11",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
