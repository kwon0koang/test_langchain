{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langserve import RemoteRunnable\n",
    "import bs4\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드 (.env)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "llm = OllamaFunctions(model=\"EEVE-Korean-Instruct-10.8B-v1.0:latest\", format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "# 로컬 DB 불러오기\n",
    "MY_FAISS_INDEX = \"MY_FAISS_INDEX\"\n",
    "vectorstore1 = FAISS.load_local(MY_FAISS_INDEX, \n",
    "                               embeddings, \n",
    "                               allow_dangerous_deserialization=True)\n",
    "retriever1 = vectorstore1.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}) # 유사도 높은 5문장 추출\n",
    "MY_PDF_INDEX = \"MY_PDF_INDEX\"\n",
    "vectorstore2 = FAISS.load_local(MY_PDF_INDEX, \n",
    "                               embeddings, \n",
    "                               allow_dangerous_deserialization=True)\n",
    "retriever2 = vectorstore2.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}) # 유사도 높은 5문장 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Tool(name='web_search', description='엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x1487dd6c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x317e52ea0>, search_kwargs={'k': 5}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\\\n\\\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x1487ddbc0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x317e52ea0>, search_kwargs={'k': 5}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\\\n\\\\n')), Tool(name='pdf_search', description='생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x1487dd6c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x317dffec0>, search_kwargs={'k': 5}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\\\n\\\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x1487ddbc0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x317dffec0>, search_kwargs={'k': 5}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\\\n\\\\n'))]\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "retriever_tool1 = create_retriever_tool(\n",
    "    retriever1,\n",
    "    name=\"web_search\",\n",
    "    description=\"엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다\",\n",
    ")\n",
    "\n",
    "retriever_tool2 = create_retriever_tool(\n",
    "    retriever2,\n",
    "    name=\"pdf_search\",\n",
    "    description=\"생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool1, retriever_tool2]\n",
    "tools\n",
    "\n",
    "# class Add(BaseModel): \n",
    "#     a: int = Field(..., description=\"First integer\")\n",
    "#     b: int = Field(..., description=\"Second integer\")\n",
    "    \n",
    "# class Multiply(BaseModel): \n",
    "#     a: int = Field(..., description=\"First integer\")\n",
    "#     b: int = Field(..., description=\"Second integer\")\n",
    "    \n",
    "# tools = [Add, Multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_with_tools = llm.bind_tools(tools=tools)\n",
    "# response = llm_with_tools.invoke(\"What is 3*12=? Also, What is 11+43?\")\n",
    "# print(f\"response: {response}\")\n",
    "# print(f\"tool_calls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 19\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[1;32m      2\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mquestion에 알맞는 답을 하기 위해 어떤 tool을 사용하면 좋을지 tool 하나를 선택해줘\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ),\n\u001b[1;32m     16\u001b[0m ])\n\u001b[1;32m     18\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 19\u001b[0m     \u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstr(tools)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRunnablePassthrough()\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# | llm\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/test-langchain-PJ4Uqdqm-py3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:433\u001b[0m, in \u001b[0;36m__ror__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compose this runnable with another object to create a RunnableSequence.\"\"\"\u001b[39;00m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(\u001b[38;5;28mself\u001b[39m, coerce_to_runnable(other))\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    432\u001b[0m     other: Union[\n\u001b[0;32m--> 433\u001b[0m         Runnable[Other, Any],\n\u001b[1;32m    434\u001b[0m         Callable[[Other], Any],\n\u001b[1;32m    435\u001b[0m         Callable[[Iterator[Other]], Iterator[Any]],\n\u001b[1;32m    436\u001b[0m         Mapping[\u001b[38;5;28mstr\u001b[39m, Union[Runnable[Other, Any], Callable[[Other], Any], Any]],\n\u001b[1;32m    437\u001b[0m     ],\n\u001b[1;32m    438\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunnableSerializable[Other, Output]:\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compose this runnable with another object to create a RunnableSequence.\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RunnableSequence(coerce_to_runnable(other), \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/test-langchain-PJ4Uqdqm-py3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:4975\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/test-langchain-PJ4Uqdqm-py3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:3007\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, steps__, **kwargs)\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackManager\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;66;03m# setup callbacks\u001b[39;00m\n\u001b[0;32m-> 3007\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m   3008\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m   3009\u001b[0m     inheritable_callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   3010\u001b[0m     local_callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3015\u001b[0m     local_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3016\u001b[0m )\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;66;03m# start the root run\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/test-langchain-PJ4Uqdqm-py3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:4977\u001b[0m, in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "question에 알맞는 답을 하기 위해 어떤 tool을 사용하면 좋을지 tool 하나를 선택해줘\n",
    "\n",
    "<tools>\n",
    "{tools}\n",
    "</tools>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "# answer :\n",
    "\"\"\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "chain = (\n",
    "    {\"tools\": \"str(tools)\", \"question\": \"RunnablePassthrough()\"}\n",
    "    | prompt \n",
    "    # | llm\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-langchain-lw2NDlv9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
