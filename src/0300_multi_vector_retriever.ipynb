{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2caa89",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab90775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fake_id_1', Document(page_content='fake whole document 1')),\n",
       " ('fake_id_2', Document(page_content='fake whole document 2'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# 원본 문서 데이터\n",
    "docstore = InMemoryStore()\n",
    "docs = [\n",
    "    (\"fake_id_1\", Document(page_content=\"fake whole document 1\")),\n",
    "    (\"fake_id_2\", Document(page_content=\"fake whole document 2\")),\n",
    "]\n",
    "\n",
    "# docstore에 원본 문서 저장\n",
    "docstore.mset(docs)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc9dd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['02c71d29-239e-4d5b-9248-9cff8c0e53ad',\n",
       " 'a000cb15-4495-4101-9049-f23df74ac2e4',\n",
       " '6a094ae1-2a44-435f-ab08-de2afb04891a']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 서브 문서 데이터\n",
    "sub_docs = [\n",
    "    Document(\n",
    "        page_content=\"A snippet from a larger document discussing cats.\",\n",
    "        metadata={\"doc_id\": \"fake_id_1\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A snippet from a larger document discussing discourse.\",\n",
    "        metadata={\"doc_id\": \"fake_id_1\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A snippet from a larger document discussing chocolate.\",\n",
    "        metadata={\"doc_id\": \"fake_id_2\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 임베딩 초기화\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "# FAISS 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents([Document(page_content=\"\")], embeddings)\n",
    "\n",
    "# vectorstore에 서브 문서 저장\n",
    "vectorstore.add_documents(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6591add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.storage import InMemoryByteStore\n",
    "\n",
    "# MultiVectorRetriever 초기화\n",
    "id_key = \"doc_id\"\n",
    "multi_vector_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=docstore,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f7808d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': 'fake_id_2'}, page_content='A snippet from a larger document discussing chocolate.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorstore 검색 결과 보기\n",
    "multi_vector_retriever.vectorstore.similarity_search(\"chocolate\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a5653e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='fake whole document 2'),\n",
       " Document(page_content='fake whole document 1')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# docstore 검색 결과 보기 (vectorstore에 서브 문서들 중 유사도가 높은 서브 문서에 링크되어 있는 원본 문서 내용을 리턴)\n",
    "multi_vector_retriever.invoke(\"chocolate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c8684d",
   "metadata": {},
   "source": [
    "# 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e26ad432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 문서 로드 및 분할\n",
    "loader = TextLoader(\"../assets/ai-story.txt\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 임베딩 초기화\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "# FAISS 벡터 저장소 생성\n",
    "vectorstore = FAISS.from_documents(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cae334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Scikit Learn\\n\\nScikit-learn은 Python 언어를 위한 또 다른 핵심 라이브러리로, 기계 학습의 다양한 알고리즘을 구현하기 위해 설계되었습니다. 이 라이브러리는 2007년 David Cournapeau에 의해 프로젝트가 시작되었으며, 그 후로 커뮤니티의 광범위한 기여를 받아 현재까지 발전해왔습니다. Scikit-learn은 분류, 회귀, 군집화, 차원 축소 등 다양한 기계 학습 작업을 지원하며, 사용하기 쉬운 API와 함께 제공되어 연구자와 개발자가 복잡한 데이터 과학 문제를 해결할 수 있도록 돕습니다.\\n\\n핵심 특징 중 하나는 다양한 기계 학습 모델을 일관된 인터페이스로 제공한다는 점입니다. 이는 사용자가 알고리즘 간에 쉽게 전환할 수 있게 하여, 최적의 모델을 찾는 과정을 단순화합니다. 또한, Scikit-learn은 사전 처리, 모델 선택, 평가 지표 등 기계 학습 파이프라인의 다른 단계에 필요한 도구들을 포함하고 있습니다. 이는 연구자와 개발자가 데이터를 더 효율적으로 처리하고, 모델의 성능을 정확히 평가할 수 있게 해줍니다.\\n\\nScikit-learn의 강점은 그의 범용성에 있습니다. 이는 다양한 산업과 연구 분야에서 사용될 수 있으며, 소규모 데이터셋부터 대규모 데이터셋까지 다양한 크기의 데이터를 처리할 수 있습니다. 또한, 오픈 소스 프로젝트로서, Scikit-learn은 지속적인 개선과 업데이트가 이루어지며, 사용자 커뮤니티로부터의 피드백과 기여를 받아 발전해 나갑니다.\\n\\n기계 학습 분야에 있어서, Scikit-learn은 특히 초보자에게 친화적인 학습 자원을 제공함으로써, 복잡한 이론과 알고리즘을 이해하는 데 중요한 역할을 합니다. 이러한 접근성과 범용성은 Scikit-learn을 기계 학습을 시작하는 이들에게 인기 있는 선택지로 만들었습니다.\\n\\nNLP\\n\\nNLP(자연어 처리)는 인간의 언어를 이해하고 해석하는 컴퓨터 알고리즘과 기술의 집합입니다. 이 분야는 컴퓨터 과학, 인공 지능, 언어학의 교차점에 위치하며, 텍스트와 음성 데이터를 처리하여 사람과 컴퓨터 간의 상호작용을 보다 자연스럽고 효율적으로 만드는 것을 목표로 합니다. NLP의 주요 응용 분야로는 기계 번역, 감정 분석, 음성 인식, 자동 요약, 챗봇 개발 등이 있으며, 이러한 기술은 정보 검색, 교육, 의료, 고객 서비스 등 다양한 분야에서 활용됩니다.\\n\\nNLP의 핵심 과제 중 하나는 자연어의 모호성과 다양성을 처리하는 것입니다. 인간 언어는 복잡하고, 문맥에 따라 그 의미가 달라질 수 있으며, 같은 단어나 구문이 다양한 의미로 사용될 수 있습니다. 이러한 언어의 특성으로 인해, NLP 시스템은 텍스트의 문법적 구조를 파악하고, 문맥을 분석하여 의미를 정확하게 이해할 수 있어야 합니다. 이를 위해 NLP는 통계학, 기계 학습, 딥 러닝과 같은 다양한 수학적 및 계산적 방법론을 활용합니다.\\n\\n최근 몇 년 동안, 딥 러닝 기반의 NLP 모델, 특히 변환기(Transformer) 아키텍처와 같은 신경망 모델의 발전으로 인해, 자연어 이해와 생성 분야에서 놀라운 진보가 이루어졌습니다. 이러한 모델들은 대규모의 언어 데이터에서 학습하여, 문장의 문맥을 효과적으로 파악하고, 보다 정교한 언어 이해 및 생성 능력을 제공합니다.\\n\\nNLP의 발전은 사람과 컴퓨터 간의 소통 방식을 근본적으로 변화시켰습니다. 예를 들어, 자연어를 이해할 수 있는 인터페이스를 통해 사용자는 복잡한 쿼리나 명령어를 사용하지 않고도 정보를 검색하거나 서비스를 이용할 수 있게 되었습니다. 또한, 자동 번역 시스템의 발전으로 언어 장벽이 낮아지고 있으며, 감정 분석 기술을 통해 소셜 미디어나 고객 리뷰에서 유용한 인사이트를 추출할 수 있게 되었습니다.\\n\\nNLP는 계속해서 발전하고 있으며, 이 분야의 연구와 기술 혁신은 인간 언어의 복잡성을 더 깊이 이해하고, 인간과 기계 간의 상호작용을 더욱 풍부하고 의미 있게 만드는 데 기여할 것입니다.\\n\\nScipy\\n\\nSciPy는 과학 계산을 위한 중심적인 파이썬 라이브러리 중 하나로, 고급 수학 함수, 알고리즘, 그리고 편리한 도구를 제공합니다. 이 라이브러리는 2001년에 Travis Oliphant에 의해 처음 개발되었으며, 그 이후로 수학, 과학, 엔지니어링 커뮤니티에 광범위하게 사용되고 있습니다. SciPy는 NumPy 배열 객체 위에 구축되어 있으며, NumPy의 기능을 확장하여 다양한 과학 및 공학 분야에서 필요로 하는 특정한 기능과 유틸리티를 제공합니다.\\n\\nSciPy의 주요 모듈에는 최적화, 선형 대수, 적분, 보간, 특수 함수, 신호 처리, 이미지 처리 등이 포함됩니다. 이러한 모듈들은 고급 수학적 연산과 과학적 분석을 수행할 수 있는 강력한 도구를 제공합니다. 예를 들어, 최적화 모듈을 사용하면 함수의 최소값을 찾거나, 방정식 시스템의 해를 구할 수 있습니다. 선형 대수 모듈을 통해서는 행렬 분해, 고유값 분석, 선형 시스템 해법 등을 계산할 수 있습니다.\\n\\nSciPy 라이브러리는 연구자와 엔지니어가 복잡한 수학적 문제를 효율적으로 해결할 수 있도록 설계되었습니다. 그 사용법은 상대적으로 간단하며, Python의 다른 과학 기술 스택과 함께 사용될 때 그 잠재력이 극대화됩니다. 예를 들어, Matplotlib과 결합하여 과학적 데이터를 시각화할 수 있고, Pandas와 함께 데이터 분석을 수행할 수 있습니다.\\n\\nSciPy의 개발은 오픈 소스 커뮤니티의 기여를 통해 이루어지며, 지속적인 개선과 업데이트가 진행되고 있습니다. 이는 라이브러리가 최신 과학적 방법론과 계산 기술을 반영하도록 보장합니다. SciPy의 사용과 배포는 BSD 라이선스 하에 이루어져, 학술 연구는 물론 상업적 응용 프로그램에도 자유롭게 사용될 수 있습니다.\\n\\n종합적으로, SciPy는 과학 계산에 필요한 광범위한 기능을 제공하며, 파이썬을 과학, 엔지니어링, 수학 분야의 연구와 개발에 적합한 언어로 만드는 데 핵심적인 역할을 합니다.\\n\\nHuggingFace\\n\\nHugging Face는 자연어 처리(NLP) 분야에서 선도적인 역할을 하는 기술 회사로, 인공 지능(AI) 연구와 응용 프로그램 개발을 위한 다양한 오픈 소스 도구와 라이브러리를 제공합니다. 2016년에 설립된 이 회사는 특히 \\'Transformers\\' 라이브러리를 통해 큰 인기를 얻었습니다. Transformers 라이브러리는 BERT, GPT, RoBERTa, T5와 같은 최신의 변환기(Transformer) 기반 모델을 쉽게 사용할 수 있게 해주며, Python 프로그래밍 언어로 작성되어 있습니다. 이 라이브러리의 주요 목적은 최신의 NLP 기술을 쉽고 효율적으로 접근할 수 있도록 하는 것입니다.\\n\\nHugging Face의 Transformers 라이브러리는 다양한 NLP 작업에 활용될 수 있습니다. 이에는 텍스트 분류, 정보 추출, 질문 응답, 요약 생성, 텍스트 생성 등이 포함되며, 다양한 언어에 대한 지원도 제공합니다. 라이브러리는 사전 훈련된 모델을 포함하고 있어, 사용자가 복잡한 모델을 처음부터 훈련시키지 않고도, 빠르게 고성능의 NLP 시스템을 구축할 수 있게 합니다.\\n\\nHugging Face는 또한 \\'Model Hub\\'를 운영하고 있습니다. 이는 수천 개의 사전 훈련된 모델과 데이터셋을 호스팅하는 플랫폼으로, 연구자와 개발자가 자신의 모델을 공유하고 다른 사람들의 모델을 쉽게 찾아 사용할 수 있게 합니다. Model Hub를 통해 사용자는 특정 NLP 작업에 최적화된 모델을 검색하고, 직접 훈련시킨 모델을 커뮤니티와 공유할 수 있습니다.\\n\\nHugging Face는 또한 AI 연구 커뮤니티에 대한 기여를 넘어, 윤리적 AI 개발과 모델의 공정성 및 투명성에 대한 중요성을 강조합니다. 회사는 AI 기술의 사회적 영향에 대해 적극적으로 논의하고, 모델 배포 시 발생할 수 있는 윤리적 문제를 해결하기 위한 가이드라인을 제공하려 노력합니다.\\n\\n종합적으로 볼 때, Hugging Face는 NLP 및 AI 분야에서 중요한 자원을 제공하는 회사로, 오픈 소스 기여와 커뮤니티 구축을 통해 AI 기술의 발전과 보급에 기여하고 있습니다. 이를 통해 연구자, 개발자, 기업 등 다양한 사용자가 최신 AI 기술을 쉽게 접근하고 활용할 수 있는 환경을 조성하고 있습니다.\\n\\nAttention is all you need\\n\\n\"Attention Is All You Need\"는 2017년에 발표된 논문으로, 변환기(Transformer) 모델의 아키텍처를 처음으로 소개한 연구입니다. Ashish Vaswani와 그의 공동 연구자들에 의해 작성된 이 논문은 자연어 처리(NLP)와 기계 학습 분야에 큰 영향을 미쳤습니다. 변환기 모델은 이전의 순환 신경망(RNN)이나 합성곱 신경망(CNN)에 의존하던 방식에서 벗어나, 전적으로 \\'어텐션 메커니즘(Attention Mechanism)\\'을 사용하여 정보를 처리합니다. 이로 인해 모델의 학습 속도와 효율성이 크게 향상되었습니다.\\n\\n어텐션 메커니즘은 입력 데이터의 서로 다른 부분에 대해 모델이 얼마나 많은 \\'주의\\'를 기울여야 하는지를 결정합니다. 특히, 변환기 모델에서 사용되는 \\'셀프 어텐션(Self-Attention)\\'은 입력 데이터 내의 각 요소가 서로 얼마나 관련이 있는지를 계산하여, 모델이 문맥을 더 잘 이해할 수 있게 합니다. 이는 특히 문장 내에서 단어 간의 관계를 파악하는 데 매우 효과적이며, 문장의 길이에 관계없이 일정한 연산 시간으로 처리할 수 있습니다.\\n\\n\"Attention Is All You Need\" 논문은 변환기 아키텍처를 기반으로 한 \\'멀티헤드 어텐션(Multi-Head Attention)\\' 기법을 도입했습니다. 이는 여러 개의 어텐션 메커니즘을 병렬로 사용하여, 서로 다른 표현 공간에서 정보를 동시에 처리함으로써 모델의 성능을 향상시킵니다. 또한, 논문은 전통적인 RNN이나 CNN에 의존하지 않음으로써 발생하는 병렬 처리의 이점을 강조하며, 이를 통해 훨씬 더 빠른 학습 속도와 효율적인 메모리 사용을 실현합니다.\\n\\n변환기 모델의 이러한 혁신적인 접근 방식은 NLP를 비롯한 여러 분야에서 큰 변화를 가져왔습니다. BERT, GPT, RoBERTa 등의 후속 모델들은 모두 \"Attention Is All You Need\" 논문에서 제시된 변환기 아키텍처를 기반으로 하며, 이들 모델은 텍스트 분류, 요약, 번역, 질문 응답 시스템 등 다양한 작업에서 인상적인 성능을 보여줍니다.\\n\\n이 논문은 기계 학습 및 NLP 분야에서 기존의 접근 방식을 재고하고, 어텐션 메커니즘의 중요성을 강조함으로써 연구와 개발의 새로운 방향을 제시했습니다. \"Attention Is All You Need\"는 그 자체로 혁신적인 연구 성과일 뿐만 아니라, AI 기술의 발전에 있어 중대한 이정표로 평가받고 있습니다.\\n\\nARIMA (자기회귀 누적 이동평균), SARIMA (계절성 자기회귀 누적 이동평균), 그리고 SARIMAX (계절성 자기회귀 누적 이동평균 외부 변수)는 시계열 데이터 분석과 예측을 위한 통계 모델입니다. 이들은 시계열 데이터의 패턴을 이해하고 미래 값을 예측하는 데 널리 사용되며, 경제학, 금융, 기상학 등 다양한 분야에서 응용됩니다. 각 모델의 특징과 차이점을 교수처럼 전문적인 어조로 설명하겠습니다.\\n\\nARIMA (자기회귀 누적 이동평균)\\n\\nARIMA 모델은 비계절적 시계열 데이터를 분석하고 예측하기 위해 설계되었습니다. 이 모델은 세 가지 주요 구성 요소를 기반으로 합니다: 자기회귀(AR) 부분, 차분(I) 부분, 그리고 이동평균(MA) 부분. AR 부분은 이전 관측값의 영향을 모델링하며, I 부분은 데이터를 안정화하는 데 필요한 차분의 횟수를 나타냅니다. MA 부분은 이전 예측 오차의 영향을 모델링합니다. ARIMA 모델은 비계절적 변동성을 가진 데이터에서 유용하게 사용됩니다.\\n\\nSARIMA (계절성 자기회귀 누적 이동평균)\\n\\nSARIMA 모델은 ARIMA 모델을 확장한 것으로, 계절적 변동성을 포함한 시계열 데이터를 분석하고 예측하는 데 적합합니다. SARIMA는 추가적으로 계절성 자기회귀(SAR) 부분, 계절성 차분의 정도, 그리고 계절성 이동평균(SMA) 부분을 모델에 포함시킵니다. 이를 통해 모델은 비계절적 패턴뿐만 아니라 계절적 변동성까지 포괄적으로 고려할 수 있습니다. SARIMA 모델은 주기적인 패턴을 보이는 데이터에 특히 유용합니다.\\n\\nSARIMAX (계절성 자기회귀 누적 이동평균 외부 변수)\\n\\nSARIMAX 모델은 SARIMA에 외부 설명 변수(또는 외생 변수)를 포함시킬 수 있는 확장된 형태입니다. 이 외부 변수들은 시계열 데이터에 영향을 미칠 수 있는 추가적인 정보(예: 경제 지표, 날씨 조건 등)를 모델에 제공합니다. SARIMAX 모델은 이러한 외부 변수들의 영향을 고려함으로써, 예측의 정확도를 더욱 향상시킬 수 있습니다. 이 모델은 복잡한 시계열 데이터에서 다양한 요인들의 영향을 모델링하고자 할 때 유용하게 사용됩니다.\\n\\n각 모델은 특정 유형의 시계열 데이터에 대한 분석과 예측에 있어 강점을 가지며, 선택하는 모델은 분석하고자 하는 데이터의 특성과 요구사항에 따라 달라집니다. ARIMA는 기본적인 비계절적 시계열 분석에 적합하고\\n\\n, SARIMA는 계절적 패턴을 고려해야 하는 경우에 사용됩니다. SARIMAX는 외부 요인을 모델에 포함시켜야 할 때 가장 적합한 선택입니다.\\n\\nWord2Vec\\n\\nWord2Vec은 자연어 처리(NLP) 분야에서 널리 사용되는 획기적인 단어 임베딩 기법 중 하나입니다. 2013년 Google의 연구팀에 의해 개발되었으며, 단어를 벡터 공간에 매핑함으로써 컴퓨터가 단어의 의미를 수치적으로 이해할 수 있게 합니다. Word2Vec의 핵심 아이디어는 비슷한 맥락에서 사용되는 단어들은 비슷한 벡터를 가진다는 것입니다. 이를 통해 단어 간의 의미적 유사성과 관계를 벡터 연산을 통해 표현할 수 있습니다.\\n\\nWord2Vec은 크게 두 가지 모델 아키텍처로 구성됩니다: Continuous Bag-of-Words (CBOW)와 Skip-Gram입니다. CBOW 모델은 주변 단어(맥락)를 기반으로 특정 단어를 예측하는 반면, Skip-Gram 모델은 하나의 단어로부터 주변 단어들을 예측합니다. 두 모델 모두 딥러닝이 아닌, 단순화된 신경망 구조를 사용하여 대규모 텍스트 데이터에서 학습할 수 있으며, 매우 효율적입니다.\\n\\nWord2Vec의 벡터 표현은 다양한 NLP 작업에 활용될 수 있습니다. 예를 들어, 단어의 유사도 측정, 문장이나 문서의 벡터 표현 생성, 기계 번역, 감정 분석 등이 있습니다. 또한, 벡터 연산을 통해 단어 간의 의미적 관계를 추론하는 것이 가능해집니다. 예를 들어, \"king\" - \"man\" + \"woman\"과 같은 벡터 연산을 수행하면, 결과적으로 \"queen\"과 유사한 벡터를 가진 단어를 찾을 수 있습니다.\\n\\nWord2Vec의 성공 이후, 이와 유사한 다른 단어 임베딩 기법들도 개발되었습니다. 그러나 Word2Vec은 그 간결함과 효율성, 높은 성능으로 인해 여전히 광범위하게 사용되며, NLP 분야에서 기본적인 도구로 자리 잡았습니다. Word2Vec는 단순한 텍스트 데이터를 통해 복잡한 언어의 의미 구조를 학습할 수 있는 강력한 방법을 제공함으로써, 컴퓨터가 인간 언어를 이해하는 방식을 혁신적으로 개선하였습니다.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d0713e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약 체인 생성\n",
    "llm = ChatOllama(model=\"ko-gemma-2-9b-it.Q5_K_M:latest\")\n",
    "summarize_chain = (\n",
    "    ChatPromptTemplate.from_template(\"다음 텍스트를 1-2문장으로 요약해주세요: {text}\")\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 각 분할에 대한 요약 생성\n",
    "summaries = []\n",
    "for split in splits:\n",
    "    summary = summarize_chain.invoke({\"text\": split.page_content})\n",
    "    summaries.append(summary)\n",
    "\n",
    "# MultiVectorRetriever 생성\n",
    "store = InMemoryStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "multi_vector_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key=id_key,\n",
    "    search_kwargs={\"k\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40749199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scikit-learn은 Python에서 기계 학습 알고리즘을 구현하기 위한 핵심 라이브러리로, 분류, 회귀, 군집화 등 다양한 작업을 지원합니다. 사용하기 쉬운 API를 통해 연구자와 개발자들이 데이터 과학 문제를 효율적으로 해결할 수 있도록 돕습니다.  \\n\\n\\n',\n",
       " 'Scikit-learn은 다양한 기계 학습 모델을 일관된 인터페이스로 제공하여 사용자들이 쉽게 알고리즘을 전환하고 최적의 모델을 찾을 수 있도록 돕는 강력한 도구입니다. 또한, 데이터 전처리부터 모델 평가까지 필요한 다양한 도구들을 포함하고 있으며, 오픈 소스로서 지속적인 발전을 이루고 있습니다. \\n\\n\\n',\n",
       " 'Scikit-learn은 기계 학습 초보자를 위한 친화적인 학습 자원을 제공하여 복잡한 이론과 알고리즘을 이해하는 데 도움을 주며, 이로 인해 기계 학습 시작자들에게 인기 있는 선택지가 되었습니다. \\n\\nNLP는 컴퓨터가 인간의 언어를 이해하고 처리하도록 하는 기술로, 기계 번역, 감정 분석, 음성 인식 등 다양한 분야에 활용됩니다. \\n\\n\\n',\n",
       " '자연어 처리(NLP)의 핵심 과제는 인간 언어의 모호성과 다양성을 해결하는 데 있습니다. 최근 딥러닝, 특히 변환기 모델의 발전으로 인해 NLP 시스템은 문맥 분석 및 의미 이해 능력을 크게 향상시켜 자연어를 더 정확하게 처리하고 생성할 수 있게 되었습니다.',\n",
       " 'NLP는 사람과 컴퓨터 간 소통 방식을 바꿔주었으며, 자연어 이해를 통한 정보 검색, 자동 번역, 감정 분석 등 다양한 분야에서 활용되고 있습니다. 앞으로도 NLP 연구는 인간 언어를 더 깊이 이해하고 인간-기계 상호작용을 향상시킬 것입니다. \\n\\n\\n',\n",
       " 'SciPy는 NumPy를 기반으로 한 파이썬 라이브러리로, 과학 계산을 위한 다양한 고급 수학 함수, 알고리즘, 유틸리티를 제공합니다. 최적화, 선형 대수, 적분 등 다양한 분야의 모듈을 통해 수학적 연산과 과학적 분석을 효율적으로 수행할 수 있습니다.',\n",
       " 'SciPy는 연구자와 엔지니어가 복잡한 수학적 문제를 효율적으로 해결할 수 있도록 설계된 Python 라이브러리로, Matplotlib, Pandas와 같은 다른 라이브러리와의 연동을 통해 다양한 과학 계산 작업을 수행할 수 있습니다.  SciPy는 오픈 소스 커뮤니티의 기여를 통해 지속적으로 발전하며, BSD 라이선스로 인해 다양한 분야에서 자유롭게 사용될 수 있습니다. \\n\\n\\n',\n",
       " \"Hugging Face는 자연어 처리 분야를 선도하는 기술 회사로, 특히 변환기 기반 모델을 쉽게 사용할 수 있도록 하는 'Transformers' 라이브러리를 통해 유명합니다. 이 라이브러리는 BERT, GPT, RoBERTa, T5와 같은 최신 모델을 Python으로 제공하여 NLP 기술 접근성을 높입니다.\",\n",
       " \"Hugging Face Transformers 라이브러리는 다양한 자연어 처리 작업에 활용 가능하며, 사전 훈련된 모델을 제공하여 사용자가 빠르고 효율적으로 고성능 NLP 시스템을 구축할 수 있도록 지원합니다. 또한, 수천 개의 모델과 데이터셋을 공유하는 플랫폼인 'Model Hub'를 통해 사용자는 필요한 모델을 쉽게 찾고, 자신의 모델을 공유할 수 있습니다.\",\n",
       " 'Hugging Face는 오픈소스 NLP 모델과 도구를 제공하며, AI 연구 커뮤니티를 활성화하고 윤리적인 AI 개발을 위한 노력도 병행하고 있습니다. 이를 통해 다양한 사용자들이 AI 기술에 쉽게 접근하고 활용할 수 있는 환경을 조성하고 있습니다. \\n\\n\\n',\n",
       " '2017년에 발표된 \"Attention Is All You Need\" 논문은 자연어 처리 분야에 큰 영향을 미친 변환기 모델을 처음 소개했습니다. 변환기 모델은 순환 신경망이나 합성곱 신경망 대신 \\'어텐션 메커니즘\\'만을 사용하여 정보를 처리함으로써 학습 속도와 효율성을 크게 향상시켰습니다.',\n",
       " '어텐션 메커니즘은 모델이 입력 데이터의 중요 부분에 집중할 수 있도록 도와주는 역할을 합니다. 특히, 셀프 어텐션은 입력 데이터 내 각 요소 간의 관련성을 분석하여 문맥 이해를 향상시키고, 문장 길이에 관계없이 효율적으로 처리됩니다.',\n",
       " '\"Attention Is All You Need\" 논문은 멀티헤드 어텐션 기법을 통해 RNN이나 CNN 없이도 효율적인 병렬 처리를 가능하게 하는 변환기 아키텍처를 제시했습니다. 이러한 혁신적인 접근 방식은 BERT, GPT, RoBERTa 등 다양한 후속 모델의 기반이 되어 NLP 분야를 크게 변화시켰습니다. \\n\\n\\n',\n",
       " '이 논문은 기계 학습 분야에서 주목할 만한 변화를 가져온 \"Attention Is All You Need\" 연구를 소개하며, 이 연구가 어텐션 메커니즘의 중요성을 강조하며 AI 기술 발전에 큰 영향을 미쳤음을 설명합니다. \\n\\nARIMA는 과거 데이터의 자기회귀(자신과의 상관관계)와 이동평균(이전 기간의 데이터)을 이용하여 시계열 데이터의 패턴을 분석하고 미래 값을 예측하는 통계 모델입니다.  \\n',\n",
       " 'ARIMA 모델은 시간 데이터의 과거 값과 예측 오차를 활용하여 비계절적 시계열 데이터를 분석하고 예측하는 데 사용됩니다. SARIMA는 ARIMA 모델을 계절성을 가진 데이터에 적용한 확장된 버전입니다.',\n",
       " 'SARIMA 모델은 계절성을 고려하여 시계열 데이터를 분석하고 예측하는 데 사용되는 ARIMA 모델의 확장형입니다. SARIMAX는 SARIMA 모델에 추가로 외부 변수를 포함시켜 더욱 정확한 예측을 가능하게 합니다.',\n",
       " 'SARIMAX 모델은 계절성을 고려하는 SARIMA 모델에 외부 변수를 추가하여 시계열 데이터에 영향을 미칠 수 있는 추가적인 요인들을 반영하여 예측 정확도를 높이는 모델입니다. 외부 변수는 경제 지표나 날씨 조건과 같은 시계열 데이터에 영향을 미칠 수 있는 다양한 정보를 포함할 수 있습니다. \\n\\n\\n',\n",
       " 'SARIMA는 계절성을, SARIMAX는 외부 요인을 고려하여 시간 시계열 데이터를 예측하는 모델입니다. \\n\\nWord2Vec는 2013년 Google에서 개발된 단어 임베딩 기법으로, 단어를 의미에 따라 가까운 벡터로 표현하여 컴퓨터가 단어의 의미를 이해하도록 돕습니다.  \\n\\n\\n',\n",
       " 'Word2Vec은 CBOW와 Skip-Gram 두 가지 모델을 통해 단어를 벡터로 표현하는 기술입니다. 이 벡터 표현은 단어 유사도 측정, 문장 벡터화, 기계 번역, 감정 분석 등 다양한 자연어 처리 작업에 활용되며, 벡터 연산을 통해 단어 간 의미적 관계를 분석할 수 있습니다.',\n",
       " 'Word2Vec 이후 다양한 단어 임베딩 기법들이 등장했지만, 간결하고 효율적인 성능으로 인해 여전히 널리 사용되는 기본적인 NLP 도구로 자리매김했습니다. Word2Vec은 단순한 텍스트 데이터를 통해 복잡한 의미 구조를 학습하여 컴퓨터의 언어 이해를 크게 발전시켰습니다.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d295f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['154059c1-cadb-4223-a9ae-0cdd2a929a70',\n",
       " 'adac1ab4-0c20-4f60-b711-f16c886139a3',\n",
       " '67bb9b0b-c21c-412e-a6d4-121af2dc0ec2',\n",
       " 'a029cec0-b909-4813-a83c-f7df21adfa0f',\n",
       " '4ab45bda-1cb5-48e0-b136-40fba2726bb7',\n",
       " '5a6abfd4-b1ad-4556-9d61-417c4c896ff6',\n",
       " 'ebc65dca-5572-41d7-9ad8-641c566a17d0',\n",
       " 'db899e1f-3aa7-41ee-803e-67542167492d',\n",
       " '746969fd-750a-4878-a920-7b842db754af',\n",
       " '5b48556b-616e-438d-a503-11b57aabd003',\n",
       " '58d5c890-07d4-4736-becf-ec732abb324f',\n",
       " '31e688d0-795d-466b-a5ac-c499aed9f85d',\n",
       " '704c6790-6401-4110-9347-f5149b55dacb',\n",
       " '8a291253-7616-4cc0-9a0a-34d278f0ad7f',\n",
       " 'd9596e61-50f6-4958-8d5f-9cb6349fa4cb',\n",
       " '24a2364c-14f6-45d9-8357-61a069d0a3a4',\n",
       " 'e7b1b854-eeb6-46cc-984b-8d1f4b6f8a1d',\n",
       " '91235e00-ae6d-497a-8017-473c97ebd0e7',\n",
       " '08a6587c-ea4c-47c0-b223-61f2fec2e330',\n",
       " '7bb3fe82-1cea-4bff-87dd-eef201881f10']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# doc id 생성\n",
    "doc_ids = [f\"doc_{i}\" for i in range(len(splits))]\n",
    "\n",
    "# docstore에 원본 문서 저장\n",
    "multi_vector_retriever.docstore.mset(list(zip(doc_ids, splits)))\n",
    "\n",
    "summary_docs = []\n",
    "for i, summary in enumerate(summaries):  # summaries 리스트의 각 요약과 인덱스에 대해 반복\n",
    "    doc_id = doc_ids[i]  # 현재 인덱스에 해당하는 문서 ID 가져오기\n",
    "    document = Document(page_content=summary, metadata={id_key: doc_id})  # Document 객체 생성\n",
    "    summary_docs.append(document)  # 생성한 Document 객체를 리스트에 추가\n",
    "\n",
    "# vectorstore에 요약 문서 저장\n",
    "multi_vector_retriever.vectorstore.add_documents(summary_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91c929f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'store': {'doc_0': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Scikit Learn\\n\\nScikit-learn은 Python 언어를 위한 또 다른 핵심 라이브러리로, 기계 학습의 다양한 알고리즘을 구현하기 위해 설계되었습니다. 이 라이브러리는 2007년 David Cournapeau에 의해 프로젝트가 시작되었으며, 그 후로 커뮤니티의 광범위한 기여를 받아 현재까지 발전해왔습니다. Scikit-learn은 분류, 회귀, 군집화, 차원 축소 등 다양한 기계 학습 작업을 지원하며, 사용하기 쉬운 API와 함께 제공되어 연구자와 개발자가 복잡한 데이터 과학 문제를 해결할 수 있도록 돕습니다.'), 'doc_1': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='핵심 특징 중 하나는 다양한 기계 학습 모델을 일관된 인터페이스로 제공한다는 점입니다. 이는 사용자가 알고리즘 간에 쉽게 전환할 수 있게 하여, 최적의 모델을 찾는 과정을 단순화합니다. 또한, Scikit-learn은 사전 처리, 모델 선택, 평가 지표 등 기계 학습 파이프라인의 다른 단계에 필요한 도구들을 포함하고 있습니다. 이는 연구자와 개발자가 데이터를 더 효율적으로 처리하고, 모델의 성능을 정확히 평가할 수 있게 해줍니다.\\n\\nScikit-learn의 강점은 그의 범용성에 있습니다. 이는 다양한 산업과 연구 분야에서 사용될 수 있으며, 소규모 데이터셋부터 대규모 데이터셋까지 다양한 크기의 데이터를 처리할 수 있습니다. 또한, 오픈 소스 프로젝트로서, Scikit-learn은 지속적인 개선과 업데이트가 이루어지며, 사용자 커뮤니티로부터의 피드백과 기여를 받아 발전해 나갑니다.'), 'doc_2': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='기계 학습 분야에 있어서, Scikit-learn은 특히 초보자에게 친화적인 학습 자원을 제공함으로써, 복잡한 이론과 알고리즘을 이해하는 데 중요한 역할을 합니다. 이러한 접근성과 범용성은 Scikit-learn을 기계 학습을 시작하는 이들에게 인기 있는 선택지로 만들었습니다.\\n\\nNLP\\n\\nNLP(자연어 처리)는 인간의 언어를 이해하고 해석하는 컴퓨터 알고리즘과 기술의 집합입니다. 이 분야는 컴퓨터 과학, 인공 지능, 언어학의 교차점에 위치하며, 텍스트와 음성 데이터를 처리하여 사람과 컴퓨터 간의 상호작용을 보다 자연스럽고 효율적으로 만드는 것을 목표로 합니다. NLP의 주요 응용 분야로는 기계 번역, 감정 분석, 음성 인식, 자동 요약, 챗봇 개발 등이 있으며, 이러한 기술은 정보 검색, 교육, 의료, 고객 서비스 등 다양한 분야에서 활용됩니다.'), 'doc_3': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='NLP의 핵심 과제 중 하나는 자연어의 모호성과 다양성을 처리하는 것입니다. 인간 언어는 복잡하고, 문맥에 따라 그 의미가 달라질 수 있으며, 같은 단어나 구문이 다양한 의미로 사용될 수 있습니다. 이러한 언어의 특성으로 인해, NLP 시스템은 텍스트의 문법적 구조를 파악하고, 문맥을 분석하여 의미를 정확하게 이해할 수 있어야 합니다. 이를 위해 NLP는 통계학, 기계 학습, 딥 러닝과 같은 다양한 수학적 및 계산적 방법론을 활용합니다.\\n\\n최근 몇 년 동안, 딥 러닝 기반의 NLP 모델, 특히 변환기(Transformer) 아키텍처와 같은 신경망 모델의 발전으로 인해, 자연어 이해와 생성 분야에서 놀라운 진보가 이루어졌습니다. 이러한 모델들은 대규모의 언어 데이터에서 학습하여, 문장의 문맥을 효과적으로 파악하고, 보다 정교한 언어 이해 및 생성 능력을 제공합니다.'), 'doc_4': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='NLP의 발전은 사람과 컴퓨터 간의 소통 방식을 근본적으로 변화시켰습니다. 예를 들어, 자연어를 이해할 수 있는 인터페이스를 통해 사용자는 복잡한 쿼리나 명령어를 사용하지 않고도 정보를 검색하거나 서비스를 이용할 수 있게 되었습니다. 또한, 자동 번역 시스템의 발전으로 언어 장벽이 낮아지고 있으며, 감정 분석 기술을 통해 소셜 미디어나 고객 리뷰에서 유용한 인사이트를 추출할 수 있게 되었습니다.\\n\\nNLP는 계속해서 발전하고 있으며, 이 분야의 연구와 기술 혁신은 인간 언어의 복잡성을 더 깊이 이해하고, 인간과 기계 간의 상호작용을 더욱 풍부하고 의미 있게 만드는 데 기여할 것입니다.\\n\\nScipy'), 'doc_5': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Scipy\\n\\nSciPy는 과학 계산을 위한 중심적인 파이썬 라이브러리 중 하나로, 고급 수학 함수, 알고리즘, 그리고 편리한 도구를 제공합니다. 이 라이브러리는 2001년에 Travis Oliphant에 의해 처음 개발되었으며, 그 이후로 수학, 과학, 엔지니어링 커뮤니티에 광범위하게 사용되고 있습니다. SciPy는 NumPy 배열 객체 위에 구축되어 있으며, NumPy의 기능을 확장하여 다양한 과학 및 공학 분야에서 필요로 하는 특정한 기능과 유틸리티를 제공합니다.\\n\\nSciPy의 주요 모듈에는 최적화, 선형 대수, 적분, 보간, 특수 함수, 신호 처리, 이미지 처리 등이 포함됩니다. 이러한 모듈들은 고급 수학적 연산과 과학적 분석을 수행할 수 있는 강력한 도구를 제공합니다. 예를 들어, 최적화 모듈을 사용하면 함수의 최소값을 찾거나, 방정식 시스템의 해를 구할 수 있습니다. 선형 대수 모듈을 통해서는 행렬 분해, 고유값 분석, 선형 시스템 해법 등을 계산할 수 있습니다.'), 'doc_6': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='SciPy 라이브러리는 연구자와 엔지니어가 복잡한 수학적 문제를 효율적으로 해결할 수 있도록 설계되었습니다. 그 사용법은 상대적으로 간단하며, Python의 다른 과학 기술 스택과 함께 사용될 때 그 잠재력이 극대화됩니다. 예를 들어, Matplotlib과 결합하여 과학적 데이터를 시각화할 수 있고, Pandas와 함께 데이터 분석을 수행할 수 있습니다.\\n\\nSciPy의 개발은 오픈 소스 커뮤니티의 기여를 통해 이루어지며, 지속적인 개선과 업데이트가 진행되고 있습니다. 이는 라이브러리가 최신 과학적 방법론과 계산 기술을 반영하도록 보장합니다. SciPy의 사용과 배포는 BSD 라이선스 하에 이루어져, 학술 연구는 물론 상업적 응용 프로그램에도 자유롭게 사용될 수 있습니다.\\n\\n종합적으로, SciPy는 과학 계산에 필요한 광범위한 기능을 제공하며, 파이썬을 과학, 엔지니어링, 수학 분야의 연구와 개발에 적합한 언어로 만드는 데 핵심적인 역할을 합니다.\\n\\nHuggingFace'), 'doc_7': Document(metadata={'source': '../assets/ai-story.txt'}, page_content=\"HuggingFace\\n\\nHugging Face는 자연어 처리(NLP) 분야에서 선도적인 역할을 하는 기술 회사로, 인공 지능(AI) 연구와 응용 프로그램 개발을 위한 다양한 오픈 소스 도구와 라이브러리를 제공합니다. 2016년에 설립된 이 회사는 특히 'Transformers' 라이브러리를 통해 큰 인기를 얻었습니다. Transformers 라이브러리는 BERT, GPT, RoBERTa, T5와 같은 최신의 변환기(Transformer) 기반 모델을 쉽게 사용할 수 있게 해주며, Python 프로그래밍 언어로 작성되어 있습니다. 이 라이브러리의 주요 목적은 최신의 NLP 기술을 쉽고 효율적으로 접근할 수 있도록 하는 것입니다.\"), 'doc_8': Document(metadata={'source': '../assets/ai-story.txt'}, page_content=\"Hugging Face의 Transformers 라이브러리는 다양한 NLP 작업에 활용될 수 있습니다. 이에는 텍스트 분류, 정보 추출, 질문 응답, 요약 생성, 텍스트 생성 등이 포함되며, 다양한 언어에 대한 지원도 제공합니다. 라이브러리는 사전 훈련된 모델을 포함하고 있어, 사용자가 복잡한 모델을 처음부터 훈련시키지 않고도, 빠르게 고성능의 NLP 시스템을 구축할 수 있게 합니다.\\n\\nHugging Face는 또한 'Model Hub'를 운영하고 있습니다. 이는 수천 개의 사전 훈련된 모델과 데이터셋을 호스팅하는 플랫폼으로, 연구자와 개발자가 자신의 모델을 공유하고 다른 사람들의 모델을 쉽게 찾아 사용할 수 있게 합니다. Model Hub를 통해 사용자는 특정 NLP 작업에 최적화된 모델을 검색하고, 직접 훈련시킨 모델을 커뮤니티와 공유할 수 있습니다.\"), 'doc_9': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Hugging Face는 또한 AI 연구 커뮤니티에 대한 기여를 넘어, 윤리적 AI 개발과 모델의 공정성 및 투명성에 대한 중요성을 강조합니다. 회사는 AI 기술의 사회적 영향에 대해 적극적으로 논의하고, 모델 배포 시 발생할 수 있는 윤리적 문제를 해결하기 위한 가이드라인을 제공하려 노력합니다.\\n\\n종합적으로 볼 때, Hugging Face는 NLP 및 AI 분야에서 중요한 자원을 제공하는 회사로, 오픈 소스 기여와 커뮤니티 구축을 통해 AI 기술의 발전과 보급에 기여하고 있습니다. 이를 통해 연구자, 개발자, 기업 등 다양한 사용자가 최신 AI 기술을 쉽게 접근하고 활용할 수 있는 환경을 조성하고 있습니다.\\n\\nAttention is all you need'), 'doc_10': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Attention is all you need\\n\\n\"Attention Is All You Need\"는 2017년에 발표된 논문으로, 변환기(Transformer) 모델의 아키텍처를 처음으로 소개한 연구입니다. Ashish Vaswani와 그의 공동 연구자들에 의해 작성된 이 논문은 자연어 처리(NLP)와 기계 학습 분야에 큰 영향을 미쳤습니다. 변환기 모델은 이전의 순환 신경망(RNN)이나 합성곱 신경망(CNN)에 의존하던 방식에서 벗어나, 전적으로 \\'어텐션 메커니즘(Attention Mechanism)\\'을 사용하여 정보를 처리합니다. 이로 인해 모델의 학습 속도와 효율성이 크게 향상되었습니다.'), 'doc_11': Document(metadata={'source': '../assets/ai-story.txt'}, page_content=\"어텐션 메커니즘은 입력 데이터의 서로 다른 부분에 대해 모델이 얼마나 많은 '주의'를 기울여야 하는지를 결정합니다. 특히, 변환기 모델에서 사용되는 '셀프 어텐션(Self-Attention)'은 입력 데이터 내의 각 요소가 서로 얼마나 관련이 있는지를 계산하여, 모델이 문맥을 더 잘 이해할 수 있게 합니다. 이는 특히 문장 내에서 단어 간의 관계를 파악하는 데 매우 효과적이며, 문장의 길이에 관계없이 일정한 연산 시간으로 처리할 수 있습니다.\"), 'doc_12': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='\"Attention Is All You Need\" 논문은 변환기 아키텍처를 기반으로 한 \\'멀티헤드 어텐션(Multi-Head Attention)\\' 기법을 도입했습니다. 이는 여러 개의 어텐션 메커니즘을 병렬로 사용하여, 서로 다른 표현 공간에서 정보를 동시에 처리함으로써 모델의 성능을 향상시킵니다. 또한, 논문은 전통적인 RNN이나 CNN에 의존하지 않음으로써 발생하는 병렬 처리의 이점을 강조하며, 이를 통해 훨씬 더 빠른 학습 속도와 효율적인 메모리 사용을 실현합니다.\\n\\n변환기 모델의 이러한 혁신적인 접근 방식은 NLP를 비롯한 여러 분야에서 큰 변화를 가져왔습니다. BERT, GPT, RoBERTa 등의 후속 모델들은 모두 \"Attention Is All You Need\" 논문에서 제시된 변환기 아키텍처를 기반으로 하며, 이들 모델은 텍스트 분류, 요약, 번역, 질문 응답 시스템 등 다양한 작업에서 인상적인 성능을 보여줍니다.'), 'doc_13': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='이 논문은 기계 학습 및 NLP 분야에서 기존의 접근 방식을 재고하고, 어텐션 메커니즘의 중요성을 강조함으로써 연구와 개발의 새로운 방향을 제시했습니다. \"Attention Is All You Need\"는 그 자체로 혁신적인 연구 성과일 뿐만 아니라, AI 기술의 발전에 있어 중대한 이정표로 평가받고 있습니다.\\n\\nARIMA (자기회귀 누적 이동평균), SARIMA (계절성 자기회귀 누적 이동평균), 그리고 SARIMAX (계절성 자기회귀 누적 이동평균 외부 변수)는 시계열 데이터 분석과 예측을 위한 통계 모델입니다. 이들은 시계열 데이터의 패턴을 이해하고 미래 값을 예측하는 데 널리 사용되며, 경제학, 금융, 기상학 등 다양한 분야에서 응용됩니다. 각 모델의 특징과 차이점을 교수처럼 전문적인 어조로 설명하겠습니다.\\n\\nARIMA (자기회귀 누적 이동평균)'), 'doc_14': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='ARIMA (자기회귀 누적 이동평균)\\n\\nARIMA 모델은 비계절적 시계열 데이터를 분석하고 예측하기 위해 설계되었습니다. 이 모델은 세 가지 주요 구성 요소를 기반으로 합니다: 자기회귀(AR) 부분, 차분(I) 부분, 그리고 이동평균(MA) 부분. AR 부분은 이전 관측값의 영향을 모델링하며, I 부분은 데이터를 안정화하는 데 필요한 차분의 횟수를 나타냅니다. MA 부분은 이전 예측 오차의 영향을 모델링합니다. ARIMA 모델은 비계절적 변동성을 가진 데이터에서 유용하게 사용됩니다.\\n\\nSARIMA (계절성 자기회귀 누적 이동평균)'), 'doc_15': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='SARIMA (계절성 자기회귀 누적 이동평균)\\n\\nSARIMA 모델은 ARIMA 모델을 확장한 것으로, 계절적 변동성을 포함한 시계열 데이터를 분석하고 예측하는 데 적합합니다. SARIMA는 추가적으로 계절성 자기회귀(SAR) 부분, 계절성 차분의 정도, 그리고 계절성 이동평균(SMA) 부분을 모델에 포함시킵니다. 이를 통해 모델은 비계절적 패턴뿐만 아니라 계절적 변동성까지 포괄적으로 고려할 수 있습니다. SARIMA 모델은 주기적인 패턴을 보이는 데이터에 특히 유용합니다.\\n\\nSARIMAX (계절성 자기회귀 누적 이동평균 외부 변수)'), 'doc_16': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='SARIMAX (계절성 자기회귀 누적 이동평균 외부 변수)\\n\\nSARIMAX 모델은 SARIMA에 외부 설명 변수(또는 외생 변수)를 포함시킬 수 있는 확장된 형태입니다. 이 외부 변수들은 시계열 데이터에 영향을 미칠 수 있는 추가적인 정보(예: 경제 지표, 날씨 조건 등)를 모델에 제공합니다. SARIMAX 모델은 이러한 외부 변수들의 영향을 고려함으로써, 예측의 정확도를 더욱 향상시킬 수 있습니다. 이 모델은 복잡한 시계열 데이터에서 다양한 요인들의 영향을 모델링하고자 할 때 유용하게 사용됩니다.\\n\\n각 모델은 특정 유형의 시계열 데이터에 대한 분석과 예측에 있어 강점을 가지며, 선택하는 모델은 분석하고자 하는 데이터의 특성과 요구사항에 따라 달라집니다. ARIMA는 기본적인 비계절적 시계열 분석에 적합하고\\n\\n, SARIMA는 계절적 패턴을 고려해야 하는 경우에 사용됩니다. SARIMAX는 외부 요인을 모델에 포함시켜야 할 때 가장 적합한 선택입니다.\\n\\nWord2Vec'), 'doc_17': Document(metadata={'source': '../assets/ai-story.txt'}, page_content=', SARIMA는 계절적 패턴을 고려해야 하는 경우에 사용됩니다. SARIMAX는 외부 요인을 모델에 포함시켜야 할 때 가장 적합한 선택입니다.\\n\\nWord2Vec\\n\\nWord2Vec은 자연어 처리(NLP) 분야에서 널리 사용되는 획기적인 단어 임베딩 기법 중 하나입니다. 2013년 Google의 연구팀에 의해 개발되었으며, 단어를 벡터 공간에 매핑함으로써 컴퓨터가 단어의 의미를 수치적으로 이해할 수 있게 합니다. Word2Vec의 핵심 아이디어는 비슷한 맥락에서 사용되는 단어들은 비슷한 벡터를 가진다는 것입니다. 이를 통해 단어 간의 의미적 유사성과 관계를 벡터 연산을 통해 표현할 수 있습니다.'), 'doc_18': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Word2Vec은 크게 두 가지 모델 아키텍처로 구성됩니다: Continuous Bag-of-Words (CBOW)와 Skip-Gram입니다. CBOW 모델은 주변 단어(맥락)를 기반으로 특정 단어를 예측하는 반면, Skip-Gram 모델은 하나의 단어로부터 주변 단어들을 예측합니다. 두 모델 모두 딥러닝이 아닌, 단순화된 신경망 구조를 사용하여 대규모 텍스트 데이터에서 학습할 수 있으며, 매우 효율적입니다.\\n\\nWord2Vec의 벡터 표현은 다양한 NLP 작업에 활용될 수 있습니다. 예를 들어, 단어의 유사도 측정, 문장이나 문서의 벡터 표현 생성, 기계 번역, 감정 분석 등이 있습니다. 또한, 벡터 연산을 통해 단어 간의 의미적 관계를 추론하는 것이 가능해집니다. 예를 들어, \"king\" - \"man\" + \"woman\"과 같은 벡터 연산을 수행하면, 결과적으로 \"queen\"과 유사한 벡터를 가진 단어를 찾을 수 있습니다.'), 'doc_19': Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Word2Vec의 성공 이후, 이와 유사한 다른 단어 임베딩 기법들도 개발되었습니다. 그러나 Word2Vec은 그 간결함과 효율성, 높은 성능으로 인해 여전히 광범위하게 사용되며, NLP 분야에서 기본적인 도구로 자리 잡았습니다. Word2Vec는 단순한 텍스트 데이터를 통해 복잡한 언어의 의미 구조를 학습할 수 있는 강력한 방법을 제공함으로써, 컴퓨터가 인간 언어를 이해하는 방식을 혁신적으로 개선하였습니다.')}}\n"
     ]
    }
   ],
   "source": [
    "# docstore 내부적으로 어떤 데이터 구조를 사용하는지 확인\n",
    "print(vars(multi_vector_retriever.docstore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f804f4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'doc_id': 'doc_18'}, page_content='Word2Vec은 CBOW와 Skip-Gram 두 가지 모델을 통해 단어를 벡터로 표현하는 기술입니다. 이 벡터 표현은 단어 유사도 측정, 문장 벡터화, 기계 번역, 감정 분석 등 다양한 자연어 처리 작업에 활용되며, 벡터 연산을 통해 단어 간 의미적 관계를 분석할 수 있습니다.')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorstore 검색 결과 보기\n",
    "multi_vector_retriever.vectorstore.similarity_search(\"Word2Vec\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6ac8ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../assets/ai-story.txt'}, page_content='Word2Vec은 크게 두 가지 모델 아키텍처로 구성됩니다: Continuous Bag-of-Words (CBOW)와 Skip-Gram입니다. CBOW 모델은 주변 단어(맥락)를 기반으로 특정 단어를 예측하는 반면, Skip-Gram 모델은 하나의 단어로부터 주변 단어들을 예측합니다. 두 모델 모두 딥러닝이 아닌, 단순화된 신경망 구조를 사용하여 대규모 텍스트 데이터에서 학습할 수 있으며, 매우 효율적입니다.\\n\\nWord2Vec의 벡터 표현은 다양한 NLP 작업에 활용될 수 있습니다. 예를 들어, 단어의 유사도 측정, 문장이나 문서의 벡터 표현 생성, 기계 번역, 감정 분석 등이 있습니다. 또한, 벡터 연산을 통해 단어 간의 의미적 관계를 추론하는 것이 가능해집니다. 예를 들어, \"king\" - \"man\" + \"woman\"과 같은 벡터 연산을 수행하면, 결과적으로 \"queen\"과 유사한 벡터를 가진 단어를 찾을 수 있습니다.')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# docstore 검색 결과 보기 (vectorstore에 서브 문서들 중 유사도가 가장 뛰어난 서브 문서에 링크되어 있는 원본 문서 내용을 리턴)\n",
    "multi_vector_retriever.invoke(\"Word2Vec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
