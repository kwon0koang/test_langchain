{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langserve import RemoteRunnable\n",
    "import json\n",
    "import bs4\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableBranch, RunnableLambda\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from typing import List, Union\n",
    "from langchain_community.tools import Tool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드 (.env)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "# llm = OllamaFunctions(model=\"EEVE-Korean-Instruct-10.8B-v1.0:latest\", format=\"json\", temperature=0)\n",
    "eeve = ChatOllama(model=\"EEVE-Korean-Instruct-10.8B-v1.0:latest\", temperature=0)\n",
    "qwen2 = ChatOllama(model=\"qwen2:latest\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Library/Caches/pypoetry/virtualenvs/test-langchain-lw2NDlv9-py3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/user/Library/Caches/pypoetry/virtualenvs/test-langchain-lw2NDlv9-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "# 로컬 DB 불러오기\n",
    "MY_NEWS_INDEX = \"MY_NEWS_INDEX\"\n",
    "vectorstore1 = FAISS.load_local(MY_NEWS_INDEX, \n",
    "                               embeddings, \n",
    "                               allow_dangerous_deserialization=True)\n",
    "retriever1 = vectorstore1.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 유사도 높은 3문장 추출\n",
    "MY_PDF_INDEX = \"MY_PDF_INDEX\"\n",
    "vectorstore2 = FAISS.load_local(MY_PDF_INDEX, \n",
    "                               embeddings, \n",
    "                               allow_dangerous_deserialization=True)\n",
    "retriever2 = vectorstore2.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 유사도 높은 3문장 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='saved_news_search', description='\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 엔비디아의 스타트업 인수 관련 내용\\n- 퍼플렉시티 관련 내용 (회사가치, 투자 등)\\n- 라마3 관련 내용\\n', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x118b59620>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x119eae590>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x118b59800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x119eae590>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')),\n",
       " Tool(name='pdf_search', description='\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 내용\\n- 생성 AI 규제 연구 관련 내용\\n- 생성 AI 연구 관련 내용\\n', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x118b59620>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x298a324d0>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x118b59800>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x298a324d0>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool1 = create_retriever_tool(\n",
    "    retriever1,\n",
    "    name=\"saved_news_search\",\n",
    "    description=\"\"\"\n",
    "다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\n",
    "- 엔비디아의 스타트업 인수 관련 내용\n",
    "- 퍼플렉시티 관련 내용 (회사가치, 투자 등)\n",
    "- 라마3 관련 내용\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "retriever_tool2 = create_retriever_tool(\n",
    "    retriever2,\n",
    "    name=\"pdf_search\",\n",
    "    description=\"\"\"\n",
    "다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\n",
    "- 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 내용\n",
    "- 생성 AI 규제 연구 관련 내용\n",
    "- 생성 AI 연구 관련 내용\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "tools = [retriever_tool1, retriever_tool2]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_for_extract_actions = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"\"\"\n",
    "# 당신은 인간의 질문에 답변하기 위해 적절한 도구를 선택하는 AI 어시스턴트입니다. \n",
    "\n",
    "# 다음 도구들을 사용할 수 있습니다:\n",
    "# {tools}\n",
    "\n",
    "# 인간의 질문을 주의 깊게 분석하고, 가장 적절한 도구를 선택하여 답변하세요. 질문에 따라 여러 도구를 사용해야 할 수도 있습니다.\n",
    "\n",
    "# 응답 시 다음 JSON 형식을 엄격히 따라주세요:\n",
    "# ```json\n",
    "# [\n",
    "#   {{\n",
    "#     \"action\": string, // 선택한 도구의 이름 (tool_name)\n",
    "#     \"action_input\": string // 도구에 입력할 검색어 또는 질문\n",
    "#   }},\n",
    "#   {{\n",
    "#     // 다음 액션 정보\n",
    "#   }}\n",
    "# ]\n",
    "# ```\n",
    "\n",
    "# 응답 지침:\n",
    "# 1. 항상 JSON 배열로 응답하세요, 단일 도구를 사용하는 경우에도 마찬가지입니다.\n",
    "# 2. 하나의 도구만 필요한 경우, 배열에 하나의 객체만 포함시키세요.\n",
    "# 3. 여러 도구가 필요한 경우, 각 도구에 대해 별도의 객체를 배열에 추가하세요.\n",
    "# 4. 액션의 순서가 중요한 경우, 배열 내 객체의 순서로 표현하세요.\n",
    "# 5. 이 JSON 형식으로만 응답하고, 다른 설명이나 추가 텍스트는 포함하지 마세요.\n",
    "# 6. 인간의 질문에 직접 답변하지 말고, 적절한 도구를 선택하여 JSON 형식으로만 응답하세요.\n",
    "# 7. 적절한 도구를 찾지 못하거나 도구 사용이 필요하지 않다고 판단되는 경우, \"action\"을 \"None\"으로, \"action_input\"을 빈 문자열로 설정하여 응답하세요.\n",
    "\n",
    "# question: {question}\n",
    "\n",
    "# answer: \n",
    "# \"\"\"\n",
    "#     )\n",
    "# ])\n",
    "prompt_for_extract_actions = hub.pull(\"kwonempty/extract-actions-for-ollama\")\n",
    "\n",
    "def get_tools(query):\n",
    "    \"\"\"\n",
    "    사용 가능한 도구들의 이름과 설명을 JSON 형식으로 반환\n",
    "    \"\"\"\n",
    "    # tools 리스트에서 각 도구의 이름, 설명을 딕셔너리 형태로 추출\n",
    "    tool_info = [{\"tool_name\": tool.name, \"tool_description\": tool.description} for tool in tools]\n",
    "    \n",
    "    print(f\"get_tools / tool_info: {tool_info}\")\n",
    "    \n",
    "    # tool_info 리스트를 JSON 형식으로 변환하여 반환\n",
    "    return json.dumps(tool_info, ensure_ascii=False)\n",
    "\n",
    "chain_for_extract_actions = (\n",
    "    {\"tools\": get_tools, \"question\": RunnablePassthrough()}\n",
    "    | prompt_for_extract_actions \n",
    "    | qwen2\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_tools / tool_info: [{'tool_name': 'saved_news_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 엔비디아의 스타트업 인수 관련 내용\\n- 퍼플렉시티 관련 내용 (회사가치, 투자 등)\\n- 라마3 관련 내용\\n'}, {'tool_name': 'pdf_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 내용\\n- 생성 AI 규제 연구 관련 내용\\n- 생성 AI 연구 관련 내용\\n'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"action\": \"None\",\\n    \"action_input\": \"\"\\n  }\\n]'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_for_extract_actions.invoke(\"3+4 계산해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_tools / tool_info: [{'tool_name': 'saved_news_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 엔비디아의 스타트업 인수 관련 내용\\n- 퍼플렉시티 관련 내용 (회사가치, 투자 등)\\n- 라마3 관련 내용\\n'}, {'tool_name': 'pdf_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 내용\\n- 생성 AI 규제 연구 관련 내용\\n- 생성 AI 연구 관련 내용\\n'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"action\": \"saved_news_search\",\\n    \"action_input\": \"라마3 성능\"\\n  },\\n  {\\n    \"action\": \"pdf_search\",\\n    \"action_input\": \"생성형 AI 도입에 따른 선거 규제 연구 책임자\"\\n  }\\n]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"라마3 성능은?\"\n",
    "# query = \"생성형 AI 도입에 따른 규제 연구 책임자는?\"\n",
    "query = \"라마3 성능은 어떻게 돼? 그리고 생성형 AI 도입에 따른 규제 연구 책임자는 누구야?\"\n",
    "actions_json = chain_for_extract_actions.invoke(query)\n",
    "actions_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_from_actions(actions_json: str, tools: List[Tool]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    주어진 JSON 문자열을 파싱하여 해당 액션에 대응하는 검색기를 찾아서 \n",
    "    액션을 실행 후 검색된 문서를 반환\n",
    "    \n",
    "    :param actions_json: 액션과 그 입력이 포함된 JSON 문자열\n",
    "    :param tools: 사용 가능한 도구들의 리스트\n",
    "    :return: 액션을 통해 검색된 문서들의 리스트\n",
    "    \"\"\"\n",
    "    print(f\"get_documents_from_actions / actions_json: {actions_json}\")\n",
    "    \n",
    "    # JSON 문자열을 파싱\n",
    "    try:\n",
    "        actions = json.loads(actions_json)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\"유효하지 않은 JSON 문자열\")\n",
    "\n",
    "    # 파싱된 객체가 리스트인지 확인\n",
    "    if not isinstance(actions, list):\n",
    "        raise ValueError(\"제공된 JSON은 액션 리스트를 나타내야 함\")\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # 도구 이름으로 검색기를 가져오는 함수\n",
    "    def get_retriever_by_tool_name(name: str) -> VectorStoreRetriever:\n",
    "        for tool in tools:\n",
    "            if tool.name == name:\n",
    "                return tool.func.keywords['retriever']\n",
    "        return None\n",
    "\n",
    "    # 각 액션을 처리\n",
    "    for action in actions:\n",
    "        if not isinstance(action, dict) or 'action' not in action or 'action_input' not in action:\n",
    "            continue  # 유효하지 않은 액션은 건너뜀\n",
    "\n",
    "        tool_name = action['action']\n",
    "        action_input = action['action_input']\n",
    "        print(f\"get_documents_from_actions / tool_name: {tool_name} / action_input: {action_input}\")\n",
    "        \n",
    "        if tool_name == \"None\": # 사용할 도구 없음. 바로 빈 document 리턴\n",
    "            print(f\"get_documents_from_actions / 사용할 도구 없음. 바로 빈 document 리턴\")\n",
    "            return []\n",
    "        \n",
    "        retriever = get_retriever_by_tool_name(tool_name)\n",
    "        \n",
    "        if retriever:\n",
    "            # 액션 입력으로 검색기 실행\n",
    "            retrieved_docs = retriever.invoke(action_input)\n",
    "            documents.extend(retrieved_docs)\n",
    "        \n",
    "    print(f\"get_documents_from_actions / len(documents): {len(documents)}\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_documents_from_actions / actions_json: [\n",
      "  {\n",
      "    \"action\": \"saved_news_search\",\n",
      "    \"action_input\": \"라마3 성능\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"pdf_search\",\n",
      "    \"action_input\": \"생성형 AI 도입에 따른 선거 규제 연구 책임자\"\n",
      "  }\n",
      "]\n",
      "get_documents_from_actions / tool_name: saved_news_search / action_input: 라마3 성능\n",
      "get_documents_from_actions / tool_name: pdf_search / action_input: 생성형 AI 도입에 따른 선거 규제 연구 책임자\n",
      "get_documents_from_actions / len(documents): 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"라마 3 벤치마크 결과 (사진=메타)\\n\\n\\n라마 3는 객관식 문제(MMLU)와 코딩(HumanEval)에는 강하지만, 70B의 경우 수학 단어 문제(MATH) 해결이나 대학원생 수준의 객관식 문제(GPQA)에서는 제미나이 프로 1.5에 떨어졌다.\\xa0\\n특히 인간 선호도에서 경쟁 모델을 앞서는 것으로 알려졌다.\\n조언 요청, 브레인스토밍, 분류, 비공개 질문 답변, 코딩, 창의적인 글쓰기, 추출, 공개 질문 답변, 추론, 재작성 및 요약 등 12가지 주요 사용 사례를 포함한 1800개\\xa0프롬프트\\xa0구축\\xa0데이터셋에 대한 인간 평가에서 오픈AI의 'GPT-3.5', 미스트랄 7B, 클로드 3 소네트보다 높게 평가됐다.\\n\\n\\n라마 3 인간 평가 결과 (사진=메타)\", metadata={'source': 'https://www.aitimes.com/news/articleView.html?idxno=158943'}),\n",
       " Document(page_content='라마 3 인간 평가 결과 (사진=메타)\\n\\n\\n허깅페이스에 따르면, 라마 3는 공개 후 몇시간만에 LLM 리더보드\\xa01위에 오르며 역대 가장 빠른 1위 달성 기록을 세웠다.\\n또 이전 라마 1과 2를 기반으로 3만개 이상의 새로운 모델이 출시됐으며, 라마 2 모델은 1700억번 다운로드됐다는 통계치도 공개해 눈길을 모았다.\\xa0\\n다만 라마 3는 완전한 오픈 소스가 아니다.\\xa0연구용 및 상업용으로 모두 사용할 수 있지만, 개발자가 다른 생성 모델을 훈련하기 위해 모델을 사용하는 것을 금지한다.\\n\\n\\n메타 AI (사진=메타)', metadata={'source': 'https://www.aitimes.com/news/articleView.html?idxno=158943'}),\n",
       " Document(page_content='특히 15조개 이상의 토큰을 동원, 학습량이 라마 2 대비 7배 이상 많으며 코드량은 4배 더 많다. 다만 데이터셋은 공개하지 않았다.\\n이후 미세조정에는 일상적인 질문부터 과학·기술·공학·수학(STEM), 코딩, 역사 지식에 이르기까지 다양한 분야의 데이터셋이 사용됐다. 훈련\\xa0규모를 확대하는 것은 물론, 고도화된 ‘지시 미세조정(instruction fine-tuning)’ 과정도 진행했다.\\xa0\\n또\\xa0라마 3는 라마 2보다 2배 큰 8000토큰의 컨텍스트 길이를 지원한다.\\n오픈 소스라는 점을 감안, 안전하고 책임감 있는 개발과 사용을 위한 다양한 안전장치도 마련했다고 밝혔다. 전문가와 자동화된 도구를 활용한 레드팀 테스트를 통해 부적절한 답변의 가능성을 최소화했다고 전했다.', metadata={'source': 'https://www.aitimes.com/news/articleView.html?idxno=158943'}),\n",
       " Document(page_content='ii\\n【2023년도 중앙선거관리위원회 정책연구용역 보고서】\\n『생성형 AI 신기술 도입에 따른 \\n선거 규제 연구』\\n연구책임자 : \\n김\\n 주\\n 희(국 립 부 경 대 학 교)\\n공동연구자 :\\n차\\n 재\\n 권(국 립 부 경 대 학 교)\\n김\\n 현\\n 정(동 아 대 학 교)\\n조\\n 성\\n 복(국 민 대 학 교)\\n연구보조원 : \\n박\\n 서\\n 현(국 립 부 경 대 학 교)\\n권\\n 수\\n 민(국 립 부 경 대 학 교)\\n본 연구보고서는 2023년도 중앙선거관리위원회 정책연구용역 과제로서 연구내용은 중앙\\n선거관리위원회의 공식 견해가 아님.', metadata={'source': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'file_path': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'page': 1, 'total_pages': 227, 'format': 'PDF 1.4', 'title': '', 'author': 'fpqlt', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20231228104945+09'00'\", 'modDate': \"D:20231228104945+09'00'\", 'trapped': ''}),\n",
       " Document(page_content='연구책임자 : \\n김\\n 주\\n 희(국 립 부 경 대 학 교)\\n공동연구자 :\\n차\\n 재\\n 권(국 립 부 경 대 학 교)\\n김\\n 현\\n 정(동 아 대 학 교)\\n조\\n 성\\n 복(국 민 대 학 교)\\n연구보조원 : \\n박\\n 서\\n 현(국 립 부 경 대 학 교)\\n권\\n 수\\n 민(국 립 부 경 대 학 교)\\n국립부경대학교 산학협력단\\n2023년도 중앙선거관리위원회 정책연구용역 보고서\\n생성형 AI 신기술 도입에 따른 \\n선거 규제 연구', metadata={'source': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'file_path': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'page': 0, 'total_pages': 227, 'format': 'PDF 1.4', 'title': '', 'author': 'fpqlt', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20231228104945+09'00'\", 'modDate': \"D:20231228104945+09'00'\", 'trapped': ''}),\n",
       " Document(page_content='의 법적 책임이 불분명한 상황이다. 다수의 국가가 AI 규제를 준비하는 \\n가운데, 미국과 EU를 중심으로 생성형 AI에 대한 규제 입법에 나서고 \\n있다.\\n○본 연구는 생성형 AI 관련 제도를 주도하는 국가의 사례 연구를 통해 \\n한국에서 발생할 수 있는 다양한 문제에 대비하는 정책적 방향성을 설\\n정하는 것을 목적으로 한다.\\n나. 연구 수행 범위: 중범위 메타 분석\\n○시간적 범위\\n- 2000년대 이후 SNS(social media) 도입과 빅데이터의 선거 활용에 따\\n른 선거 영향 및 문제점을 분석한다.', metadata={'source': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'file_path': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'page': 6, 'total_pages': 227, 'format': 'PDF 1.4', 'title': '', 'author': 'fpqlt', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20231228104945+09'00'\", 'modDate': \"D:20231228104945+09'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_documents_from_actions(actions_json, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "너는 정확하고 신뢰할 수 있는 답변을 제공하는 유능한 업무 보조자야.\n",
    "아래의 context를 사용해서 question에 대한 답변을 작성해줘.\n",
    "\n",
    "다음 지침을 따라주세요:\n",
    "1. 답변은 반드시 한국어로 작성해야 해.\n",
    "2. context에 있는 정보만을 사용해서 답변해야 해.\n",
    "3. 정답을 확실히 알 수 없다면 \"주어진 정보로는 답변하기 어렵습니다.\"라고만 말해.\n",
    "4. 답변 시 추측하거나 개인적인 의견을 추가하지 마.\n",
    "5. 가능한 간결하고 명확하게 답변해.\n",
    "\n",
    "# question: \n",
    "{question}\n",
    "\n",
    "# context: \n",
    "{context}\n",
    "\n",
    "# answer:\n",
    "\"\"\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "너는 정확하고 신뢰할 수 있는 답변을 제공하는 유능한 업무 보조자야.\n",
    "다음 질문에 최선을 다해서 대답해줘.\n",
    "\n",
    "# question: \n",
    "{question}\n",
    "\n",
    "# answer:\n",
    "\"\"\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "retrieved_docs = []\n",
    "def get_page_contents_with_metadata(docs) -> str: \n",
    "    \"\"\"\n",
    "    문서 리스트를 받아 각 문서의 본문 내용과 출처를 포함한 문자열을 생성\n",
    "    \"\"\"\n",
    "    global retrieved_docs\n",
    "    retrieved_docs = docs\n",
    "    \n",
    "    result = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i > 0:\n",
    "            result += \"\\n\\n\"\n",
    "        result += f\"## 본문: {doc.page_content}\\n### 출처: {doc.metadata['source']}\"\n",
    "    return result\n",
    "\n",
    "def get_retrieved_docs_string(query) -> str:\n",
    "    \"\"\"\n",
    "    쿼리에 따라 문서를 검색하고, 해당 문서들의 본문 내용과 출처를 포함한 문자열을 반환\n",
    "    \"\"\"\n",
    "    actions_json = chain_for_extract_actions.invoke(query)\n",
    "    docs = get_documents_from_actions(actions_json, tools)\n",
    "    return get_page_contents_with_metadata(docs)\n",
    "\n",
    "def get_metadata_sources(docs) -> str: \n",
    "    \"\"\"\n",
    "    문서 리스트에서 각 문서의 출처 추출해서 문자열로 반환\n",
    "    \"\"\"\n",
    "    sources = set()\n",
    "    for doc in docs:\n",
    "        source = doc.metadata['source']\n",
    "        is_pdf = source.endswith('.pdf')\n",
    "        if (is_pdf):\n",
    "            file_path = doc.metadata['source']\n",
    "            file_name = os.path.basename(file_path)\n",
    "            source = f\"{file_name} ({int(doc.metadata['page']) + 1}페이지)\"\n",
    "        sources.add(source)\n",
    "    return \"\\n\".join(sources)\n",
    "\n",
    "def check_context(inputs: dict) -> bool:\n",
    "    \"\"\"\n",
    "    context 존재 여부 확인\n",
    "    \n",
    "    :return: 문자열이 비어있지 않으면 True, 비어있으면 False\n",
    "    \"\"\"\n",
    "    result = bool(inputs['context'].strip())\n",
    "    print(f\"check_context / result: {result}\")\n",
    "    return result\n",
    "\n",
    "def parse(ai_message: AIMessage) -> str:\n",
    "    \"\"\"\n",
    "    AI 메시지 파싱해서 내용에 출처 추가\n",
    "    \"\"\"\n",
    "    return f\"{ai_message.content}\\n\\n[출처]\\n{get_metadata_sources(retrieved_docs)}\"\n",
    "\n",
    "with_context_chain = (\n",
    "    RunnablePassthrough()\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"context\": x[\"context\"],\n",
    "        \"question\": x[\"question\"]\n",
    "    })\n",
    "    | agent_prompt\n",
    "    | eeve\n",
    "    | parse\n",
    ")\n",
    "\n",
    "without_context_chain = (\n",
    "    RunnablePassthrough()\n",
    "    | RunnableLambda(lambda x: {\"question\": x[\"question\"]})\n",
    "    | default_prompt\n",
    "    | eeve\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "agent_chain = (\n",
    "    {\"context\": get_retrieved_docs_string, \"question\": RunnablePassthrough()}\n",
    "    | RunnableBranch(\n",
    "        (lambda x: check_context(x), with_context_chain),\n",
    "        without_context_chain  # default\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_tools / tool_info: [{'tool_name': 'saved_news_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 엔비디아의 스타트업 인수 관련 내용\\n- 퍼플렉시티 관련 내용 (회사가치, 투자 등)\\n- 라마3 관련 내용\\n'}, {'tool_name': 'pdf_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 내용\\n- 생성 AI 규제 연구 관련 내용\\n- 생성 AI 연구 관련 내용\\n'}]\n",
      "get_documents_from_actions / actions_json: [\n",
      "  {\n",
      "    \"action\": \"saved_news_search\",\n",
      "    \"action_input\": \"라마3 성능\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"pdf_search\",\n",
      "    \"action_input\": \"생성형 AI 도입에 따른 선거 규제 연구 책임자\"\n",
      "  }\n",
      "]\n",
      "get_documents_from_actions / tool_name: saved_news_search / action_input: 라마3 성능\n",
      "get_documents_from_actions / tool_name: pdf_search / action_input: 생성형 AI 도입에 따른 선거 규제 연구 책임자\n",
      "get_documents_from_actions / len(documents): 6\n",
      "check_context / result: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'라마3의 성능은 객관식 문제(MMLU)와 코딩(HumanEval)에서 강점을 보이며, 특히 인간 선호도 측면에서 경쟁 모델을 앞서고 있습니다. 그러나 수학 단어 문제(MATH) 해결이나 대학원생 수준의 객관식 문제(GPQA)에서는 제미나이 프로 1.5에 비해 뒤처집니다.\\n\\n라마3의 규제 연구 책임자는 국립부경대학교 김주희 교수입니다. 이 연구는 생성형 AI 도입과 관련된 다양한 문제에 대비하기 위한 정책적 방향성을 설정하는 것을 목적으로 합니다. 연구 범위는 중범위 메타 분석으로, 2000년대 이후 소셜 미디어(SNS) 도입 및 빅데이터의 선거 활용에 따른 영향력과 문제점을 다룹니다.\\n\\n[출처]\\n생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf (2페이지)\\nhttps://www.aitimes.com/news/articleView.html?idxno=158943\\n생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf (7페이지)\\n생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf (1페이지)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent_chain.invoke(\"퍼플렉시티가 투자받은 금액?\") # saved_news_search / '퍼플렉시티는 투자받은 금액이 약 6300만 달러(약 860억 원)이며, 회사 가치는 10억 달러(약 1조 3760억 원) 이상으로 평가받았습니다.'\n",
    "# agent_chain.invoke(\"생성형 AI 도입에 따른 규제 연구 책임자는?\") # pdf_search / '해당 문서에 따르면, 생성형 AI 도입과 관련된 규제 연구를 담당하는 연구 책임자는 김주희 교수님입니다.'\n",
    "agent_chain.invoke(\"라마3 성능은 어떻게 돼? 그리고 생성형 AI 도입에 따른 규제 연구 책임자는 누구야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_tools / tool_info: [{'tool_name': 'saved_news_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 엔비디아의 스타트업 인수 관련 내용\\n- 퍼플렉시티 관련 내용 (회사가치, 투자 등)\\n- 라마3 관련 내용\\n'}, {'tool_name': 'pdf_search', 'tool_description': '\\n다음과 같은 정보를 검색할 때에는 이 도구를 사용해야 한다:\\n- 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 내용\\n- 생성 AI 규제 연구 관련 내용\\n- 생성 AI 연구 관련 내용\\n'}]\n",
      "get_documents_from_actions / actions_json: [\n",
      "  {\n",
      "    \"action\": \"None\",\n",
      "    \"action_input\": \"\"\n",
      "  }\n",
      "]\n",
      "get_documents_from_actions / tool_name: None / action_input: \n",
      "get_documents_from_actions / 사용할 도구 없음. 바로 빈 document 리턴\n",
      "check_context / result: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'물론이죠, 도와드리겠습니다!\\n\\n12 + 34 = 46입니다.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\"12+34 계산해줘\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-langchain-lw2NDlv9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
