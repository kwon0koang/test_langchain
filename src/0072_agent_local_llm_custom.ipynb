{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langserve import RemoteRunnable\n",
    "import json\n",
    "import bs4\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from typing import List, Union\n",
    "from langchain_community.tools import Tool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드 (.env)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "# llm = OllamaFunctions(model=\"EEVE-Korean-Instruct-10.8B-v1.0:latest\", format=\"json\", temperature=0)\n",
    "eeve = ChatOllama(model=\"EEVE-Korean-Instruct-10.8B-v1.0:latest\", temperature=0)\n",
    "qwen2 = ChatOllama(model=\"qwen2:latest\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs = {'device': 'cpu'}, # 모델이 CPU에서 실행되도록 설정. GPU를 사용할 수 있는 환경이라면 'cuda'로 설정할 수도 있음\n",
    "    encode_kwargs = {'normalize_embeddings': True}, # 임베딩 정규화. 모든 벡터가 같은 범위의 값을 갖도록 함. 유사도 계산 시 일관성을 높여줌\n",
    ")\n",
    "\n",
    "# 로컬 DB 불러오기\n",
    "MY_NEWS_INDEX = \"MY_NEWS_INDEX\"\n",
    "vectorstore1 = FAISS.load_local(MY_NEWS_INDEX, \n",
    "                               embeddings, \n",
    "                               allow_dangerous_deserialization=True)\n",
    "retriever1 = vectorstore1.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 유사도 높은 3문장 추출\n",
    "MY_PDF_INDEX = \"MY_PDF_INDEX\"\n",
    "vectorstore2 = FAISS.load_local(MY_PDF_INDEX, \n",
    "                               embeddings, \n",
    "                               allow_dangerous_deserialization=True)\n",
    "retriever2 = vectorstore2.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3}) # 유사도 높은 3문장 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='saved_news_search', description='엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다. 엔비디아, 퍼플렉시티, 라마3 관련 정보는 이 도구를 사용해야 한다', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x114aef420>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x299ae58d0>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x114aef600>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x299ae58d0>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')),\n",
       " Tool(name='pdf_search', description='생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다. 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보는 이 도구를 사용해야 한다', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x114aef420>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x29a455110>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x114aef600>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x29a455110>, search_kwargs={'k': 3}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "retriever_tool1 = create_retriever_tool(\n",
    "    retriever1,\n",
    "    name=\"saved_news_search\",\n",
    "    description=\"엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다. 엔비디아, 퍼플렉시티, 라마3 관련 정보는 이 도구를 사용해야 한다\",\n",
    ")\n",
    "\n",
    "retriever_tool2 = create_retriever_tool(\n",
    "    retriever2,\n",
    "    name=\"pdf_search\",\n",
    "    description=\"생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다. 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보는 이 도구를 사용해야 한다\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool1, retriever_tool2]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_for_select_tool = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "당신은 인간의 질문에 답변하기 위해 적절한 도구를 선택하는 AI 어시스턴트입니다. \n",
    "\n",
    "다음 도구들을 사용할 수 있습니다:\n",
    "{tools}\n",
    "\n",
    "인간의 질문을 주의 깊게 분석하고, 가장 적절한 도구를 선택하여 답변하세요. 질문에 따라 여러 도구를 사용해야 할 수도 있습니다.\n",
    "\n",
    "응답 시 다음 JSON 형식을 엄격히 따라주세요:\n",
    "```json\n",
    "[\n",
    "  {{\n",
    "    \"action\": string, // 선택한 도구의 이름 (tool_name)\n",
    "    \"action_input\": string // 도구에 입력할 검색어 또는 질문\n",
    "  }},\n",
    "  {{\n",
    "    // 다음 액션 정보\n",
    "  }}\n",
    "]\n",
    "```\n",
    "\n",
    "응답 지침:\n",
    "1. 항상 JSON 배열로 응답하세요, 단일 도구를 사용하는 경우에도 마찬가지입니다.\n",
    "2. 하나의 도구만 필요한 경우, 배열에 하나의 객체만 포함시키세요.\n",
    "3. 여러 도구가 필요한 경우, 각 도구에 대해 별도의 객체를 배열에 추가하세요.\n",
    "4. 액션의 순서가 중요한 경우, 배열 내 객체의 순서로 표현하세요.\n",
    "5. 이 JSON 형식으로만 응답하고, 다른 설명이나 추가 텍스트는 포함하지 마세요.\n",
    "6. 인간의 질문에 직접 답변하지 말고, 적절한 도구를 선택하여 JSON 형식으로만 응답하세요.\n",
    "\n",
    "question: {question}\n",
    "\n",
    "answer: \n",
    "\"\"\"\n",
    "    )\n",
    "])\n",
    "\n",
    "def get_tools(query):\n",
    "    \"\"\"\n",
    "    사용 가능한 도구들의 이름과 설명을 JSON 형식으로 반환\n",
    "    \"\"\"\n",
    "    # tools 리스트에서 각 도구의 이름, 설명을 딕셔너리 형태로 추출\n",
    "    tool_info = [{\"tool_name\": tool.name, \"tool_description\": tool.description} for tool in tools]\n",
    "    \n",
    "    print(f\"get_tools / tool_info: {tool_info}\")\n",
    "    \n",
    "    # tool_info 리스트를 JSON 형식으로 변환하여 반환\n",
    "    return json.dumps(tool_info, ensure_ascii=False)\n",
    "\n",
    "chain_for_select_actions = (\n",
    "    {\"tools\": get_tools, \"question\": RunnablePassthrough()}\n",
    "    | prompt_for_select_tool \n",
    "    | qwen2\n",
    "    | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_tools / [{'tool_name': 'saved_news_search', 'tool_description': '엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다. 엔비디아, 퍼플렉시티, 라마3 관련 정보는 이 도구를 사용해야 한다'}, {'tool_name': 'pdf_search', 'tool_description': '생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다. 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보는 이 도구를 사용해야 한다'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"action\": \"saved_news_search\",\\n    \"action_input\": \"라마3 성능\"\\n  },\\n  {\\n    \"action\": \"pdf_search\",\\n    \"action_input\": \"생성형 AI 신기술 도입에 따른 선거 규제 연구 책임자\"\\n  }\\n]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"라마3 성능은?\"\n",
    "# query = \"생성형 AI 도입에 따른 규제 연구 책임자는?\"\n",
    "query = \"라마3 성능은 어떻게 돼? 그리고 생성형 AI 도입에 따른 규제 연구 책임자는 누구야?\"\n",
    "actions_json = chain_for_select_actions.invoke(query)\n",
    "actions_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_documents_from_actions / tool_name: saved_news_search / action_input: 라마3 성능\n",
      "get_documents_from_actions / tool_name: pdf_search / action_input: 생성형 AI 신기술 도입에 따른 선거 규제 연구 책임자\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"라마 3 벤치마크 결과 (사진=메타)\\n\\n\\n라마 3는 객관식 문제(MMLU)와 코딩(HumanEval)에는 강하지만, 70B의 경우 수학 단어 문제(MATH) 해결이나 대학원생 수준의 객관식 문제(GPQA)에서는 제미나이 프로 1.5에 떨어졌다.\\xa0\\n특히 인간 선호도에서 경쟁 모델을 앞서는 것으로 알려졌다.\\n조언 요청, 브레인스토밍, 분류, 비공개 질문 답변, 코딩, 창의적인 글쓰기, 추출, 공개 질문 답변, 추론, 재작성 및 요약 등 12가지 주요 사용 사례를 포함한 1800개\\xa0프롬프트\\xa0구축\\xa0데이터셋에 대한 인간 평가에서 오픈AI의 'GPT-3.5', 미스트랄 7B, 클로드 3 소네트보다 높게 평가됐다.\\n\\n\\n라마 3 인간 평가 결과 (사진=메타)\", metadata={'source': 'https://www.aitimes.com/news/articleView.html?idxno=158943'}),\n",
       " Document(page_content='라마 3 인간 평가 결과 (사진=메타)\\n\\n\\n허깅페이스에 따르면, 라마 3는 공개 후 몇시간만에 LLM 리더보드\\xa01위에 오르며 역대 가장 빠른 1위 달성 기록을 세웠다.\\n또 이전 라마 1과 2를 기반으로 3만개 이상의 새로운 모델이 출시됐으며, 라마 2 모델은 1700억번 다운로드됐다는 통계치도 공개해 눈길을 모았다.\\xa0\\n다만 라마 3는 완전한 오픈 소스가 아니다.\\xa0연구용 및 상업용으로 모두 사용할 수 있지만, 개발자가 다른 생성 모델을 훈련하기 위해 모델을 사용하는 것을 금지한다.\\n\\n\\n메타 AI (사진=메타)', metadata={'source': 'https://www.aitimes.com/news/articleView.html?idxno=158943'}),\n",
       " Document(page_content='특히 15조개 이상의 토큰을 동원, 학습량이 라마 2 대비 7배 이상 많으며 코드량은 4배 더 많다. 다만 데이터셋은 공개하지 않았다.\\n이후 미세조정에는 일상적인 질문부터 과학·기술·공학·수학(STEM), 코딩, 역사 지식에 이르기까지 다양한 분야의 데이터셋이 사용됐다. 훈련\\xa0규모를 확대하는 것은 물론, 고도화된 ‘지시 미세조정(instruction fine-tuning)’ 과정도 진행했다.\\xa0\\n또\\xa0라마 3는 라마 2보다 2배 큰 8000토큰의 컨텍스트 길이를 지원한다.\\n오픈 소스라는 점을 감안, 안전하고 책임감 있는 개발과 사용을 위한 다양한 안전장치도 마련했다고 밝혔다. 전문가와 자동화된 도구를 활용한 레드팀 테스트를 통해 부적절한 답변의 가능성을 최소화했다고 전했다.', metadata={'source': 'https://www.aitimes.com/news/articleView.html?idxno=158943'}),\n",
       " Document(page_content='ii\\n【2023년도 중앙선거관리위원회 정책연구용역 보고서】\\n『생성형 AI 신기술 도입에 따른 \\n선거 규제 연구』\\n연구책임자 : \\n김\\n 주\\n 희(국 립 부 경 대 학 교)\\n공동연구자 :\\n차\\n 재\\n 권(국 립 부 경 대 학 교)\\n김\\n 현\\n 정(동 아 대 학 교)\\n조\\n 성\\n 복(국 민 대 학 교)\\n연구보조원 : \\n박\\n 서\\n 현(국 립 부 경 대 학 교)\\n권\\n 수\\n 민(국 립 부 경 대 학 교)\\n본 연구보고서는 2023년도 중앙선거관리위원회 정책연구용역 과제로서 연구내용은 중앙\\n선거관리위원회의 공식 견해가 아님.', metadata={'source': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'file_path': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'page': 1, 'total_pages': 227, 'format': 'PDF 1.4', 'title': '', 'author': 'fpqlt', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20231228104945+09'00'\", 'modDate': \"D:20231228104945+09'00'\", 'trapped': ''}),\n",
       " Document(page_content='연구책임자 : \\n김\\n 주\\n 희(국 립 부 경 대 학 교)\\n공동연구자 :\\n차\\n 재\\n 권(국 립 부 경 대 학 교)\\n김\\n 현\\n 정(동 아 대 학 교)\\n조\\n 성\\n 복(국 민 대 학 교)\\n연구보조원 : \\n박\\n 서\\n 현(국 립 부 경 대 학 교)\\n권\\n 수\\n 민(국 립 부 경 대 학 교)\\n국립부경대학교 산학협력단\\n2023년도 중앙선거관리위원회 정책연구용역 보고서\\n생성형 AI 신기술 도입에 따른 \\n선거 규제 연구', metadata={'source': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'file_path': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'page': 0, 'total_pages': 227, 'format': 'PDF 1.4', 'title': '', 'author': 'fpqlt', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20231228104945+09'00'\", 'modDate': \"D:20231228104945+09'00'\", 'trapped': ''}),\n",
       " Document(page_content='3\\n1.2 연구의 내용과 방법\\n가. 연구 내용\\n○첫 번째, 생성형 AI 신기술의 기술 분류에 따른 선거 활용 시 문제점을 \\n유형화한다. 텍스트, 코드 생성, 이미지, 음성합성 기술(Speech \\nsynthesis), 영상 및 3D 모델, 오디오 등 각각 영역에서의 생성형 AI 기\\n술이 선거에서 어떠한 유형의 문제를 일으킬 수 있을지 유형화하며 관\\n련 사례를 제시하고, 2000년대 이후 빅데이터의 선거 활용에 따른 선거 \\n영향과 문제점을 분석한다. 그리고 신기술의 선거 분야 내 활용 관련 \\n국내외 선행연구를 검토하여 생성형 AI의 선거 과정에서 활용된 혹은 \\n잠재적으로 활용될 가능성에 대한 검토와 방향성을 제시한다. 또한 이\\n를 통해 생성형 AI의 규제 유형화와 생성형 AI의 선거 규제의 방향성에 \\n대한 논의를 통해 국가별 특징을 구별하고자 한다. \\n○두 번째, 미국, 영국, EU, 독일 등 주요 국가와 생성형 AI로 위협에 가', metadata={'source': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'file_path': '/Users/user/kykdev/7000_AI/test_langchain/assets/생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf', 'page': 8, 'total_pages': 227, 'format': 'PDF 1.4', 'title': '', 'author': 'fpqlt', 'subject': '', 'keywords': '', 'creator': 'Hwp 2018 10.0.0.9139', 'producer': 'Hancom PDF 1.3.0.538', 'creationDate': \"D:20231228104945+09'00'\", 'modDate': \"D:20231228104945+09'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_retriever_by_tool_name(name) -> VectorStoreRetriever:\n",
    "#     print(f\"get_retriever_by_tool_name / name: {name}\")\n",
    "#     for tool in tools:\n",
    "#         if tool.name == name:\n",
    "#             # print(tool.func) # functools.partial(<function _get_relevant_documents at 0x1487dd6c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x317e52ea0>, search_kwargs={'k': 5}), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n')\n",
    "#             return tool.func.keywords['retriever']\n",
    "#     return None\n",
    "\n",
    "# retriever = get_retriever_by_tool_name(selected_tool)\n",
    "# # retriever.invoke(query)\n",
    "# retriever\n",
    "\n",
    "# def get_documents_from_actions(actions_json: str, tools: List[Tool]) -> List[Document]:\n",
    "def get_documents_from_actions(actions_json, tools):\n",
    "    \"\"\"\n",
    "    Parse the given JSON string of actions, find corresponding retrievers,\n",
    "    and return documents retrieved by invoking the actions.\n",
    "    \n",
    "    :param actions_json: A JSON string containing a list of actions and their inputs\n",
    "    :param tools: A list of available tools\n",
    "    :return: A list of documents retrieved from the actions\n",
    "    \"\"\"\n",
    "    # Parse the JSON string\n",
    "    try:\n",
    "        actions = json.loads(actions_json)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(\"Invalid JSON string provided\")\n",
    "\n",
    "    # Validate that the parsed object is a list\n",
    "    if not isinstance(actions, list):\n",
    "        raise ValueError(\"The provided JSON should represent a list of actions\")\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # Function to get retriever by tool name\n",
    "    def get_retriever_by_tool_name(name: str) -> VectorStoreRetriever:\n",
    "        for tool in tools:\n",
    "            if tool.name == name:\n",
    "                return tool.func.keywords['retriever']\n",
    "        return None\n",
    "\n",
    "    # Process each action\n",
    "    for action in actions:\n",
    "        if not isinstance(action, dict) or 'action' not in action or 'action_input' not in action:\n",
    "            continue  # Skip invalid actions\n",
    "\n",
    "        tool_name = action['action']\n",
    "        action_input = action['action_input']\n",
    "        print(f\"get_documents_from_actions / tool_name: {tool_name} / action_input: {action_input}\")\n",
    "        retriever = get_retriever_by_tool_name(tool_name)\n",
    "        \n",
    "        if retriever:\n",
    "            # Invoke the retriever with the action input\n",
    "            retrieved_docs = retriever.get_relevant_documents(action_input)\n",
    "            documents.extend(retrieved_docs)\n",
    "\n",
    "    return documents\n",
    "\n",
    "get_documents_from_actions(actions_json, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_tools / [{'tool_name': 'saved_news_search', 'tool_description': '엔비디아, 퍼플렉시티, 라마3 관련 정보를 검색한다. 엔비디아, 퍼플렉시티, 라마3 관련 정보는 이 도구를 사용해야 한다'}, {'tool_name': 'pdf_search', 'tool_description': '생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보를 검색한다. 생성형 AI 신기술 도입에 따른 선거 규제 연구 관련 정보는 이 도구를 사용해야 한다'}]\n",
      "get_documents_from_actions / tool_name: saved_news_search / action_input: 라마3 성능\n",
      "get_documents_from_actions / tool_name: pdf_search / action_input: 생성형 AI 신기술 도입에 따른 선거 규제 연구 책임자\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'라마3의 성능은 객관식 문제(MMLU)와 코딩(HumanEval)에서 강점을 보이며, 특히 인간 선호도 측면에서 경쟁 모델을 앞서고 있습니다. 그러나 수학 단어 문제(MATH) 해결이나 대학원생 수준의 객관식 문제(GPQA)에서는 제미나이 프로 1.5에 비해 뒤처집니다. 라마3는 공개 후 몇 시간 만에 LLM 리더보드에서 1위를 차지하며 역대 가장 빠른 기록을 세웠습니다.\\n\\n라마3의 인간 평가 결과, 허깅페이스는 공개 후 몇 시간 만에 LLM 리더보드에서 1위에 올랐다고 언급했습니다. 또한 이전 라마 1과 2를 기반으로 한 모델이 3만 개 이상 출시되었으며, 라마 2 모델은 17억 번 다운로드되었다고 합니다. 그러나 라마 3는 완전한 오픈 소스가 아니며, 연구 및 상업적 용도로 사용 가능하지만 개발자가 다른 생성 모델을 훈련하는 것을 금지하고 있습니다.\\n\\n라마3의 안전성과 책임 있는 사용을 보장하기 위해 다양한 안전장치를 마련했습니다. 부적절한 답변 가능성을 최소화하기 위해 전문가와 자동화된 도구를 활용한 레드팀 테스트를 실시했습니다. 라마3는 라마 2보다 두 배 큰 컨텍스트 길이(8000 토큰)를 지원하며, 훈련 규모를 확대하고 지시 미세조정 과정을 거쳤습니다.\\n\\n생성형 AI 도입에 따른 규제 연구 책임자는 국립부경대학교 김주희 교수입니다. 공동연구자로는 차재권, 김현정, 조성복 교수가 있으며, 연구보조원은 박서현과 권수민입니다. 이 연구는 2023년도 중앙선거관리위원회 정책연구용역 과제로서, 생성형 AI 기술이 선거에 미치는 영향과 잠재적 문제점을 분석하고 규제 방안을 제안하고 있습니다.\\n\\n[출처]\\nhttps://www.aitimes.com/news/articleView.html?idxno=158943\\n생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf (1페이지)\\n생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf (9페이지)\\n생성형_AI_신기술_도입에_따른_선거_규제_연구_결과보고서.pdf (2페이지)'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "너는 정확하고 신뢰할 수 있는 답변을 제공하는 유능한 업무 보조자야.\n",
    "아래의 context를 사용해서 question에 대한 답변을 작성해줘.\n",
    "\n",
    "다음 지침을 따라주세요:\n",
    "1. 답변은 반드시 한국어로 작성해야 해.\n",
    "2. context에 있는 정보만을 사용해서 답변해야 해.\n",
    "3. 정답을 확실히 알 수 없다면 \"주어진 정보로는 답변하기 어렵습니다.\"라고만 말해.\n",
    "4. 답변 시 추측하거나 개인적인 의견을 추가하지 마.\n",
    "5. 가능한 간결하고 명확하게 답변해.\n",
    "\n",
    "# question: \n",
    "{question}\n",
    "\n",
    "# context: \n",
    "{context}\n",
    "\n",
    "# answer:\n",
    "\"\"\"\n",
    "    ),\n",
    "])\n",
    "\n",
    "retrieved_docs = []\n",
    "def get_page_contents_with_metadata(docs) -> str: \n",
    "    global retrieved_docs\n",
    "    retrieved_docs = docs\n",
    "    \n",
    "    result = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i > 0:\n",
    "            result += \"\\n\\n\"\n",
    "        result += f\"## 본문: {doc.page_content}\\n### 출처: {doc.metadata['source']}\"\n",
    "    return result\n",
    "\n",
    "def get_retrieved_docs(query) -> str:\n",
    "    actions_json = chain_for_select_actions.invoke(query)\n",
    "    docs = get_documents_from_actions(actions_json, tools)\n",
    "    return get_page_contents_with_metadata(docs)\n",
    "\n",
    "def get_metadata_sources(docs) -> str: \n",
    "    sources = set()\n",
    "    for doc in docs:\n",
    "        source = doc.metadata['source']\n",
    "        is_pdf = source.endswith('.pdf')\n",
    "        if (is_pdf):\n",
    "            file_path = doc.metadata['source']\n",
    "            file_name = os.path.basename(file_path)\n",
    "            source = f\"{file_name} ({int(doc.metadata['page']) + 1}페이지)\"\n",
    "        sources.add(source)\n",
    "    return \"\\n\".join(sources)\n",
    "\n",
    "def parse(ai_message: AIMessage) -> str:\n",
    "    \"\"\"Parse the AI message and add source.\"\"\"\n",
    "    return f\"{ai_message.content}\\n\\n[출처]\\n{get_metadata_sources(retrieved_docs)}\"\n",
    "\n",
    "agent_chain = (\n",
    "    {\"context\": get_retrieved_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | eeve\n",
    "    | parse\n",
    ")\n",
    "\n",
    "# agent_chain.invoke(\"퍼플렉시티가 투자받은 금액?\") # saved_news_search / '퍼플렉시티는 투자받은 금액이 약 6300만 달러(약 860억 원)이며, 회사 가치는 10억 달러(약 1조 3760억 원) 이상으로 평가받았습니다.'\n",
    "# agent_chain.invoke(\"생성형 AI 도입에 따른 규제 연구 책임자는?\") # pdf_search / '해당 문서에 따르면, 생성형 AI 도입과 관련된 규제 연구를 담당하는 연구 책임자는 김주희 교수님입니다.'\n",
    "agent_chain.invoke(\"라마3 성능은 어떻게 돼? 그리고 생성형 AI 도입에 따른 규제 연구 책임자는 누구야?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-langchain-lw2NDlv9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
